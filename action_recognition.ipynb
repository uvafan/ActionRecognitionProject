{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "res_model = models.resnet50(pretrained=True)\n",
    "# print(res_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# print(os.listdir('data/data_first_25/ApplyEyeMakeup'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imageio\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize(256),  # 1. Resize smallest side to 256.\n",
    "     transforms.CenterCrop(224), # 2. Crop center square of 224x224 pixels.\n",
    "     transforms.ToTensor(), # 3. Convert to pytorch tensor.\n",
    "     transforms.Normalize(mean = [0.485, 0.456, 0.406],  # normalize.\n",
    "                          std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "img_pil = Image.open('data/data_first_25/ApplyEyeMakeup/g01_c01/v_ApplyEyeMakeup_g01_c01_frame0.jpg')\n",
    "\n",
    "# 1. Forward propagate the image through the CNN.\n",
    "# Unsqueeze adds a dummy batch dimension needed to pass through the model.\n",
    "input_img =  test_transform(img_pil).unsqueeze(0)\n",
    "\n",
    "# print(res_model(input_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_img_list(cat,d1):\n",
    "    ret = list()\n",
    "    for frame in os.listdir('data/data_first_25/{}/{}'.format(cat,d1)):\n",
    "        img_pil = Image.open('data/data_first_25/{}/{}/{}'.format(cat,d1,frame))\n",
    "        input_img = test_transform(img_pil).unsqueeze(0)\n",
    "        ret.append(input_img)\n",
    "    return ret\n",
    "\n",
    "def createTrainAndValSet(categories,trainPercentage):\n",
    "    category_options = os.listdir('data/data_first_25')\n",
    "    category_names = category_options[:categories]\n",
    "    train_set = []\n",
    "    val_set = []\n",
    "    i=0\n",
    "    for cat in category_names:\n",
    "        for d1 in os.listdir('data/data_first_25/{}'.format(cat)):\n",
    "            r = random.uniform(0,1)\n",
    "            img_list = get_img_list(cat,d1)\n",
    "            if r < trainPercentage:\n",
    "                train_set.append((img_list,i))\n",
    "            else:\n",
    "                val_set.append((img_list,i))\n",
    "        i+=1\n",
    "    return train_set,val_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/HHTseng/video-classification/blob/master/ResNetCRNN/functions.py\n",
    "\n",
    "\n",
    "\n",
    "# 2D CNN encoder using ResNet-152 pretrained\n",
    "class ResCNNEncoder(nn.Module):\n",
    "    def __init__(self, fc_hidden1=512, fc_hidden2=512, drop_p=0.3, CNN_embed_dim=300):\n",
    "        \"\"\"Load the pretrained ResNet-152 and replace top fc layer.\"\"\"\n",
    "        super(ResCNNEncoder, self).__init__()\n",
    "\n",
    "        self.fc_hidden1, self.fc_hidden2 = fc_hidden1, fc_hidden2\n",
    "        self.drop_p = drop_p\n",
    "\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(resnet.fc.in_features, fc_hidden1)\n",
    "        self.bn1 = nn.BatchNorm1d(fc_hidden1, momentum=0.01)\n",
    "        self.fc2 = nn.Linear(fc_hidden1, fc_hidden2)\n",
    "        self.bn2 = nn.BatchNorm1d(fc_hidden2, momentum=0.01)\n",
    "        self.fc3 = nn.Linear(fc_hidden2, CNN_embed_dim)\n",
    "        \n",
    "    def forward(self, x_3d):\n",
    "        cnn_embed_seq = []\n",
    "        for t in range(x_3d.size(1)):\n",
    "            # ResNet CNN\n",
    "            with torch.no_grad():\n",
    "                x = self.resnet(x_3d[:, t, :, :, :])  # ResNet\n",
    "                x = x.view(x.size(0), -1)             # flatten output of conv\n",
    "\n",
    "            # FC layers\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.drop_p, training=self.training)\n",
    "            x = self.fc3(x)\n",
    "\n",
    "            cnn_embed_seq.append(x)\n",
    "\n",
    "        # swap time and sample dim such that (sample dim, time dim, CNN latent dim)\n",
    "        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=0).transpose_(0, 1)\n",
    "        # cnn_embed_seq: shape=(batch, time_step, input_size)\n",
    "\n",
    "        return cnn_embed_seq\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, CNN_embed_dim=300, h_RNN_layers=3, h_RNN=256, h_FC_dim=128, drop_p=0.3, num_classes=50):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.RNN_input_size = CNN_embed_dim\n",
    "        self.h_RNN_layers = h_RNN_layers   # RNN hidden layers\n",
    "        self.h_RNN = h_RNN                 # RNN hidden nodes\n",
    "        self.h_FC_dim = h_FC_dim\n",
    "        self.drop_p = drop_p\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.LSTM = nn.LSTM(\n",
    "            input_size=self.RNN_input_size,\n",
    "            hidden_size=self.h_RNN,        \n",
    "            num_layers=h_RNN_layers,       \n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(self.h_RNN, self.h_FC_dim)\n",
    "        self.fc2 = nn.Linear(self.h_FC_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, x_RNN):\n",
    "        \n",
    "        self.LSTM.flatten_parameters()\n",
    "        RNN_out, (h_n, h_c) = self.LSTM(x_RNN, None)  \n",
    "        \"\"\" h_n shape (n_layers, batch, hidden_size), h_c shape (n_layers, batch, hidden_size) \"\"\" \n",
    "        \"\"\" None represents zero initial hidden state. RNN_out has shape=(batch, time_step, output_size) \"\"\"\n",
    "\n",
    "        # FC layers\n",
    "        x = self.fc1(RNN_out[:, -1, :])   # choose RNN_out at the last time step\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.drop_p, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_used = 5\n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "batchSize = 1\n",
    "trainPercentage = 1\n",
    "\n",
    "train_set, val_set = createTrainAndValSet(categories_used,trainPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-epoch 0. Iteration 00100, Avg-Loss: 1.6671, Accuracy: 0.2000\n",
      "Train-epoch 0. Iteration 00200, Avg-Loss: 1.6688, Accuracy: 0.1950\n",
      "Train-epoch 0. Iteration 00300, Avg-Loss: 1.6480, Accuracy: 0.2233\n",
      "Train-epoch 0. Iteration 00400, Avg-Loss: 1.6613, Accuracy: 0.2100\n",
      "Train-epoch 0. Iteration 00500, Avg-Loss: 1.6609, Accuracy: 0.2060\n",
      "Train-epoch 0. Iteration 00600, Avg-Loss: 1.6570, Accuracy: 0.2133\n",
      "Train-epoch 1. Iteration 00100, Avg-Loss: 1.6325, Accuracy: 0.2100\n",
      "Train-epoch 1. Iteration 00200, Avg-Loss: 1.6307, Accuracy: 0.2400\n",
      "Train-epoch 1. Iteration 00300, Avg-Loss: 1.6325, Accuracy: 0.2467\n",
      "Train-epoch 1. Iteration 00400, Avg-Loss: 1.6222, Accuracy: 0.2650\n",
      "Train-epoch 1. Iteration 00500, Avg-Loss: 1.6264, Accuracy: 0.2520\n",
      "Train-epoch 1. Iteration 00600, Avg-Loss: 1.6251, Accuracy: 0.2517\n",
      "Train-epoch 2. Iteration 00100, Avg-Loss: 1.6490, Accuracy: 0.2300\n",
      "Train-epoch 2. Iteration 00200, Avg-Loss: 1.6538, Accuracy: 0.2450\n",
      "Train-epoch 2. Iteration 00300, Avg-Loss: 1.6510, Accuracy: 0.2367\n",
      "Train-epoch 2. Iteration 00400, Avg-Loss: 1.6456, Accuracy: 0.2425\n",
      "Train-epoch 2. Iteration 00500, Avg-Loss: 1.6470, Accuracy: 0.2400\n",
      "Train-epoch 2. Iteration 00600, Avg-Loss: 1.6355, Accuracy: 0.2500\n",
      "Train-epoch 3. Iteration 00100, Avg-Loss: 1.6499, Accuracy: 0.2400\n",
      "Train-epoch 3. Iteration 00200, Avg-Loss: 1.6457, Accuracy: 0.2200\n",
      "Train-epoch 3. Iteration 00300, Avg-Loss: 1.6345, Accuracy: 0.2300\n",
      "Train-epoch 3. Iteration 00400, Avg-Loss: 1.6320, Accuracy: 0.2300\n",
      "Train-epoch 3. Iteration 00500, Avg-Loss: 1.6305, Accuracy: 0.2220\n",
      "Train-epoch 3. Iteration 00600, Avg-Loss: 1.6257, Accuracy: 0.2333\n",
      "Train-epoch 4. Iteration 00100, Avg-Loss: 1.5989, Accuracy: 0.2300\n",
      "Train-epoch 4. Iteration 00200, Avg-Loss: 1.6120, Accuracy: 0.2400\n",
      "Train-epoch 4. Iteration 00300, Avg-Loss: 1.6104, Accuracy: 0.2500\n",
      "Train-epoch 4. Iteration 00400, Avg-Loss: 1.6139, Accuracy: 0.2375\n",
      "Train-epoch 4. Iteration 00500, Avg-Loss: 1.6187, Accuracy: 0.2400\n",
      "Train-epoch 4. Iteration 00600, Avg-Loss: 1.6148, Accuracy: 0.2450\n",
      "Train-epoch 5. Iteration 00100, Avg-Loss: 1.6090, Accuracy: 0.3200\n",
      "Train-epoch 5. Iteration 00200, Avg-Loss: 1.5863, Accuracy: 0.3150\n",
      "Train-epoch 5. Iteration 00300, Avg-Loss: 1.5905, Accuracy: 0.3033\n",
      "Train-epoch 5. Iteration 00400, Avg-Loss: 1.5890, Accuracy: 0.2900\n",
      "Train-epoch 5. Iteration 00500, Avg-Loss: 1.5957, Accuracy: 0.2780\n",
      "Train-epoch 5. Iteration 00600, Avg-Loss: 1.5958, Accuracy: 0.2733\n",
      "Train-epoch 6. Iteration 00100, Avg-Loss: 1.5837, Accuracy: 0.2500\n",
      "Train-epoch 6. Iteration 00200, Avg-Loss: 1.5891, Accuracy: 0.2500\n",
      "Train-epoch 6. Iteration 00300, Avg-Loss: 1.5725, Accuracy: 0.2733\n",
      "Train-epoch 6. Iteration 00400, Avg-Loss: 1.5930, Accuracy: 0.2475\n",
      "Train-epoch 6. Iteration 00500, Avg-Loss: 1.5961, Accuracy: 0.2500\n",
      "Train-epoch 6. Iteration 00600, Avg-Loss: 1.5965, Accuracy: 0.2533\n",
      "Train-epoch 7. Iteration 00100, Avg-Loss: 1.6300, Accuracy: 0.2600\n",
      "Train-epoch 7. Iteration 00200, Avg-Loss: 1.6017, Accuracy: 0.2800\n",
      "Train-epoch 7. Iteration 00300, Avg-Loss: 1.5913, Accuracy: 0.2733\n",
      "Train-epoch 7. Iteration 00400, Avg-Loss: 1.5863, Accuracy: 0.2750\n",
      "Train-epoch 7. Iteration 00500, Avg-Loss: 1.5924, Accuracy: 0.2740\n",
      "Train-epoch 7. Iteration 00600, Avg-Loss: 1.5789, Accuracy: 0.2817\n",
      "Train-epoch 8. Iteration 00100, Avg-Loss: 1.5764, Accuracy: 0.2000\n",
      "Train-epoch 8. Iteration 00200, Avg-Loss: 1.6094, Accuracy: 0.2100\n",
      "Train-epoch 8. Iteration 00300, Avg-Loss: 1.5794, Accuracy: 0.2433\n",
      "Train-epoch 8. Iteration 00400, Avg-Loss: 1.5781, Accuracy: 0.2400\n",
      "Train-epoch 8. Iteration 00500, Avg-Loss: 1.5748, Accuracy: 0.2500\n",
      "Train-epoch 8. Iteration 00600, Avg-Loss: 1.5733, Accuracy: 0.2517\n",
      "Train-epoch 9. Iteration 00100, Avg-Loss: 1.5522, Accuracy: 0.3200\n",
      "Train-epoch 9. Iteration 00200, Avg-Loss: 1.5652, Accuracy: 0.3100\n",
      "Train-epoch 9. Iteration 00300, Avg-Loss: 1.5662, Accuracy: 0.2933\n",
      "Train-epoch 9. Iteration 00400, Avg-Loss: 1.5659, Accuracy: 0.3025\n",
      "Train-epoch 9. Iteration 00500, Avg-Loss: 1.5518, Accuracy: 0.3140\n",
      "Train-epoch 9. Iteration 00600, Avg-Loss: 1.5550, Accuracy: 0.3067\n",
      "Train-epoch 10. Iteration 00100, Avg-Loss: 1.5501, Accuracy: 0.3500\n",
      "Train-epoch 10. Iteration 00200, Avg-Loss: 1.5449, Accuracy: 0.3050\n",
      "Train-epoch 10. Iteration 00300, Avg-Loss: 1.5581, Accuracy: 0.2800\n",
      "Train-epoch 10. Iteration 00400, Avg-Loss: 1.5606, Accuracy: 0.2850\n",
      "Train-epoch 10. Iteration 00500, Avg-Loss: 1.5528, Accuracy: 0.2940\n",
      "Train-epoch 10. Iteration 00600, Avg-Loss: 1.5493, Accuracy: 0.3000\n",
      "Train-epoch 11. Iteration 00100, Avg-Loss: 1.5341, Accuracy: 0.3100\n",
      "Train-epoch 11. Iteration 00200, Avg-Loss: 1.5459, Accuracy: 0.3100\n",
      "Train-epoch 11. Iteration 00300, Avg-Loss: 1.5373, Accuracy: 0.3267\n",
      "Train-epoch 11. Iteration 00400, Avg-Loss: 1.5319, Accuracy: 0.3200\n",
      "Train-epoch 11. Iteration 00500, Avg-Loss: 1.5303, Accuracy: 0.3140\n",
      "Train-epoch 11. Iteration 00600, Avg-Loss: 1.5491, Accuracy: 0.3033\n",
      "Train-epoch 12. Iteration 00100, Avg-Loss: 1.5630, Accuracy: 0.2600\n",
      "Train-epoch 12. Iteration 00200, Avg-Loss: 1.5491, Accuracy: 0.3050\n",
      "Train-epoch 12. Iteration 00300, Avg-Loss: 1.5637, Accuracy: 0.3100\n",
      "Train-epoch 12. Iteration 00400, Avg-Loss: 1.5618, Accuracy: 0.3050\n",
      "Train-epoch 12. Iteration 00500, Avg-Loss: 1.5442, Accuracy: 0.3160\n",
      "Train-epoch 12. Iteration 00600, Avg-Loss: 1.5414, Accuracy: 0.3167\n",
      "Train-epoch 13. Iteration 00100, Avg-Loss: 1.5447, Accuracy: 0.2800\n",
      "Train-epoch 13. Iteration 00200, Avg-Loss: 1.5348, Accuracy: 0.2950\n",
      "Train-epoch 13. Iteration 00300, Avg-Loss: 1.5420, Accuracy: 0.2967\n",
      "Train-epoch 13. Iteration 00400, Avg-Loss: 1.5342, Accuracy: 0.2950\n",
      "Train-epoch 13. Iteration 00500, Avg-Loss: 1.5402, Accuracy: 0.2960\n",
      "Train-epoch 13. Iteration 00600, Avg-Loss: 1.5474, Accuracy: 0.2967\n",
      "Train-epoch 14. Iteration 00100, Avg-Loss: 1.5452, Accuracy: 0.2500\n",
      "Train-epoch 14. Iteration 00200, Avg-Loss: 1.5297, Accuracy: 0.2750\n",
      "Train-epoch 14. Iteration 00300, Avg-Loss: 1.5303, Accuracy: 0.2900\n",
      "Train-epoch 14. Iteration 00400, Avg-Loss: 1.5351, Accuracy: 0.3000\n",
      "Train-epoch 14. Iteration 00500, Avg-Loss: 1.5342, Accuracy: 0.2980\n",
      "Train-epoch 14. Iteration 00600, Avg-Loss: 1.5338, Accuracy: 0.3067\n",
      "Train-epoch 15. Iteration 00100, Avg-Loss: 1.5152, Accuracy: 0.3100\n",
      "Train-epoch 15. Iteration 00200, Avg-Loss: 1.5368, Accuracy: 0.3200\n",
      "Train-epoch 15. Iteration 00300, Avg-Loss: 1.5255, Accuracy: 0.3333\n",
      "Train-epoch 15. Iteration 00400, Avg-Loss: 1.5134, Accuracy: 0.3325\n",
      "Train-epoch 15. Iteration 00500, Avg-Loss: 1.5162, Accuracy: 0.3260\n",
      "Train-epoch 15. Iteration 00600, Avg-Loss: 1.5042, Accuracy: 0.3333\n",
      "Train-epoch 16. Iteration 00100, Avg-Loss: 1.5064, Accuracy: 0.3100\n",
      "Train-epoch 16. Iteration 00200, Avg-Loss: 1.5137, Accuracy: 0.3000\n",
      "Train-epoch 16. Iteration 00300, Avg-Loss: 1.5098, Accuracy: 0.3367\n",
      "Train-epoch 16. Iteration 00400, Avg-Loss: 1.5042, Accuracy: 0.3500\n",
      "Train-epoch 16. Iteration 00500, Avg-Loss: 1.5122, Accuracy: 0.3440\n",
      "Train-epoch 16. Iteration 00600, Avg-Loss: 1.5046, Accuracy: 0.3483\n",
      "Train-epoch 17. Iteration 00100, Avg-Loss: 1.5427, Accuracy: 0.2700\n",
      "Train-epoch 17. Iteration 00200, Avg-Loss: 1.5158, Accuracy: 0.3150\n",
      "Train-epoch 17. Iteration 00300, Avg-Loss: 1.5351, Accuracy: 0.3200\n",
      "Train-epoch 17. Iteration 00400, Avg-Loss: 1.5346, Accuracy: 0.2975\n",
      "Train-epoch 17. Iteration 00500, Avg-Loss: 1.5320, Accuracy: 0.3100\n",
      "Train-epoch 17. Iteration 00600, Avg-Loss: 1.5232, Accuracy: 0.3183\n",
      "Train-epoch 18. Iteration 00100, Avg-Loss: 1.4383, Accuracy: 0.4400\n",
      "Train-epoch 18. Iteration 00200, Avg-Loss: 1.4971, Accuracy: 0.3700\n",
      "Train-epoch 18. Iteration 00300, Avg-Loss: 1.5064, Accuracy: 0.3500\n",
      "Train-epoch 18. Iteration 00400, Avg-Loss: 1.5216, Accuracy: 0.3300\n",
      "Train-epoch 18. Iteration 00500, Avg-Loss: 1.5168, Accuracy: 0.3280\n",
      "Train-epoch 18. Iteration 00600, Avg-Loss: 1.5199, Accuracy: 0.3283\n",
      "Train-epoch 19. Iteration 00100, Avg-Loss: 1.4457, Accuracy: 0.3800\n",
      "Train-epoch 19. Iteration 00200, Avg-Loss: 1.4837, Accuracy: 0.3450\n",
      "Train-epoch 19. Iteration 00300, Avg-Loss: 1.4823, Accuracy: 0.3467\n",
      "Train-epoch 19. Iteration 00400, Avg-Loss: 1.4968, Accuracy: 0.3450\n",
      "Train-epoch 19. Iteration 00500, Avg-Loss: 1.4929, Accuracy: 0.3480\n",
      "Train-epoch 19. Iteration 00600, Avg-Loss: 1.4975, Accuracy: 0.3433\n",
      "Train-epoch 20. Iteration 00100, Avg-Loss: 1.4889, Accuracy: 0.3400\n",
      "Train-epoch 20. Iteration 00200, Avg-Loss: 1.4461, Accuracy: 0.3550\n",
      "Train-epoch 20. Iteration 00300, Avg-Loss: 1.4882, Accuracy: 0.3333\n",
      "Train-epoch 20. Iteration 00400, Avg-Loss: 1.4940, Accuracy: 0.3425\n",
      "Train-epoch 20. Iteration 00500, Avg-Loss: 1.4950, Accuracy: 0.3440\n",
      "Train-epoch 20. Iteration 00600, Avg-Loss: 1.4871, Accuracy: 0.3483\n",
      "Train-epoch 21. Iteration 00100, Avg-Loss: 1.4900, Accuracy: 0.3400\n",
      "Train-epoch 21. Iteration 00200, Avg-Loss: 1.4793, Accuracy: 0.3550\n",
      "Train-epoch 21. Iteration 00300, Avg-Loss: 1.4902, Accuracy: 0.3433\n",
      "Train-epoch 21. Iteration 00400, Avg-Loss: 1.4780, Accuracy: 0.3575\n",
      "Train-epoch 21. Iteration 00500, Avg-Loss: 1.4893, Accuracy: 0.3480\n",
      "Train-epoch 21. Iteration 00600, Avg-Loss: 1.5021, Accuracy: 0.3417\n",
      "Train-epoch 22. Iteration 00100, Avg-Loss: 1.4407, Accuracy: 0.3800\n",
      "Train-epoch 22. Iteration 00200, Avg-Loss: 1.4816, Accuracy: 0.3550\n",
      "Train-epoch 22. Iteration 00300, Avg-Loss: 1.4935, Accuracy: 0.3500\n",
      "Train-epoch 22. Iteration 00400, Avg-Loss: 1.5097, Accuracy: 0.3425\n",
      "Train-epoch 22. Iteration 00500, Avg-Loss: 1.5082, Accuracy: 0.3420\n",
      "Train-epoch 22. Iteration 00600, Avg-Loss: 1.5117, Accuracy: 0.3450\n",
      "Train-epoch 23. Iteration 00100, Avg-Loss: 1.5242, Accuracy: 0.3300\n",
      "Train-epoch 23. Iteration 00200, Avg-Loss: 1.4846, Accuracy: 0.3550\n",
      "Train-epoch 23. Iteration 00300, Avg-Loss: 1.4871, Accuracy: 0.3500\n",
      "Train-epoch 23. Iteration 00400, Avg-Loss: 1.4917, Accuracy: 0.3625\n",
      "Train-epoch 23. Iteration 00500, Avg-Loss: 1.4966, Accuracy: 0.3440\n",
      "Train-epoch 23. Iteration 00600, Avg-Loss: 1.4962, Accuracy: 0.3433\n",
      "Train-epoch 24. Iteration 00100, Avg-Loss: 1.4550, Accuracy: 0.4000\n",
      "Train-epoch 24. Iteration 00200, Avg-Loss: 1.4268, Accuracy: 0.3900\n",
      "Train-epoch 24. Iteration 00300, Avg-Loss: 1.4504, Accuracy: 0.3600\n",
      "Train-epoch 24. Iteration 00400, Avg-Loss: 1.4382, Accuracy: 0.3825\n",
      "Train-epoch 24. Iteration 00500, Avg-Loss: 1.4455, Accuracy: 0.3780\n",
      "Train-epoch 24. Iteration 00600, Avg-Loss: 1.4443, Accuracy: 0.3783\n",
      "Train-epoch 25. Iteration 00100, Avg-Loss: 1.4401, Accuracy: 0.4100\n",
      "Train-epoch 25. Iteration 00200, Avg-Loss: 1.4093, Accuracy: 0.4200\n",
      "Train-epoch 25. Iteration 00300, Avg-Loss: 1.4405, Accuracy: 0.3867\n",
      "Train-epoch 25. Iteration 00400, Avg-Loss: 1.4450, Accuracy: 0.3875\n",
      "Train-epoch 25. Iteration 00500, Avg-Loss: 1.4371, Accuracy: 0.3960\n",
      "Train-epoch 25. Iteration 00600, Avg-Loss: 1.4564, Accuracy: 0.3767\n",
      "Train-epoch 26. Iteration 00100, Avg-Loss: 1.4282, Accuracy: 0.3400\n",
      "Train-epoch 26. Iteration 00200, Avg-Loss: 1.4727, Accuracy: 0.3600\n",
      "Train-epoch 26. Iteration 00300, Avg-Loss: 1.4975, Accuracy: 0.3467\n",
      "Train-epoch 26. Iteration 00400, Avg-Loss: 1.4873, Accuracy: 0.3475\n",
      "Train-epoch 26. Iteration 00500, Avg-Loss: 1.4882, Accuracy: 0.3520\n",
      "Train-epoch 26. Iteration 00600, Avg-Loss: 1.4876, Accuracy: 0.3467\n",
      "Train-epoch 27. Iteration 00100, Avg-Loss: 1.4211, Accuracy: 0.4200\n",
      "Train-epoch 27. Iteration 00200, Avg-Loss: 1.4284, Accuracy: 0.3900\n",
      "Train-epoch 27. Iteration 00300, Avg-Loss: 1.4432, Accuracy: 0.3833\n",
      "Train-epoch 27. Iteration 00400, Avg-Loss: 1.4412, Accuracy: 0.3775\n",
      "Train-epoch 27. Iteration 00500, Avg-Loss: 1.4401, Accuracy: 0.3760\n",
      "Train-epoch 27. Iteration 00600, Avg-Loss: 1.4450, Accuracy: 0.3717\n",
      "Train-epoch 28. Iteration 00100, Avg-Loss: 1.4886, Accuracy: 0.3700\n",
      "Train-epoch 28. Iteration 00200, Avg-Loss: 1.5151, Accuracy: 0.3450\n",
      "Train-epoch 28. Iteration 00300, Avg-Loss: 1.5052, Accuracy: 0.3533\n",
      "Train-epoch 28. Iteration 00400, Avg-Loss: 1.4976, Accuracy: 0.3625\n",
      "Train-epoch 28. Iteration 00500, Avg-Loss: 1.4753, Accuracy: 0.3620\n",
      "Train-epoch 28. Iteration 00600, Avg-Loss: 1.4690, Accuracy: 0.3667\n",
      "Train-epoch 29. Iteration 00100, Avg-Loss: 1.4675, Accuracy: 0.3800\n",
      "Train-epoch 29. Iteration 00200, Avg-Loss: 1.4334, Accuracy: 0.4050\n",
      "Train-epoch 29. Iteration 00300, Avg-Loss: 1.4539, Accuracy: 0.3767\n",
      "Train-epoch 29. Iteration 00400, Avg-Loss: 1.4570, Accuracy: 0.3800\n",
      "Train-epoch 29. Iteration 00500, Avg-Loss: 1.4631, Accuracy: 0.3680\n",
      "Train-epoch 29. Iteration 00600, Avg-Loss: 1.4584, Accuracy: 0.3767\n",
      "Train-epoch 30. Iteration 00100, Avg-Loss: 1.4527, Accuracy: 0.3400\n",
      "Train-epoch 30. Iteration 00200, Avg-Loss: 1.4178, Accuracy: 0.3600\n",
      "Train-epoch 30. Iteration 00300, Avg-Loss: 1.4059, Accuracy: 0.3800\n",
      "Train-epoch 30. Iteration 00400, Avg-Loss: 1.4263, Accuracy: 0.3875\n",
      "Train-epoch 30. Iteration 00500, Avg-Loss: 1.4327, Accuracy: 0.3940\n",
      "Train-epoch 30. Iteration 00600, Avg-Loss: 1.4389, Accuracy: 0.3850\n",
      "Train-epoch 31. Iteration 00100, Avg-Loss: 1.4749, Accuracy: 0.3400\n",
      "Train-epoch 31. Iteration 00200, Avg-Loss: 1.4795, Accuracy: 0.3500\n",
      "Train-epoch 31. Iteration 00300, Avg-Loss: 1.4474, Accuracy: 0.3733\n",
      "Train-epoch 31. Iteration 00400, Avg-Loss: 1.4504, Accuracy: 0.3675\n",
      "Train-epoch 31. Iteration 00500, Avg-Loss: 1.4331, Accuracy: 0.3820\n",
      "Train-epoch 31. Iteration 00600, Avg-Loss: 1.4380, Accuracy: 0.3767\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "learningRate = 5e-3\n",
    "epochs = 50\n",
    "\n",
    "train_accuracies = []; val_accuracies = []\n",
    "train_losses = []; val_losses = []\n",
    "\n",
    "\n",
    "def train_model(categories,lossFn,batchSize,learningRate,epochs):\n",
    "    cnn_encoder = ResCNNEncoder(CNN_embed_dim=categories).cuda()\n",
    "    rnn_decoder = DecoderRNN(num_classes=categories).cuda()\n",
    "    cnn_encoder.train()\n",
    "    rnn_decoder.train()\n",
    "\n",
    "\n",
    "    lossFn = lossFn.cuda()\n",
    "    crnn_params = list(cnn_encoder.fc1.parameters()) + \\\n",
    "                  list(cnn_encoder.fc2.parameters()) + \\\n",
    "                  list(cnn_encoder.fc3.parameters()) #+ list(rnn_decoder.parameters())\n",
    "    crnn_params = list(cnn_encoder.fc3.parameters())\n",
    "    optimizer = torch.optim.Adam(crnn_params, lr=learningRate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        shuffle(train_set)\n",
    "        correct = 0\n",
    "        cum_loss = 0\n",
    "\n",
    "        i=0\n",
    "        for video in train_set:\n",
    "            frame_list,target_cat = video\n",
    "            frame_list = torch.stack(frame_list, dim=0).transpose(0, 1).cuda()\n",
    "#             scores = rnn_decoder(cnn_encoder(frame_list))\n",
    "            scores = cnn_encoder(frame_list)\n",
    "            scores = scores[0][0].view(1,5)\n",
    "#             print(scores)\n",
    "#             print(target_cat)\n",
    "            \n",
    "            loss = lossFn(scores,torch.tensor(np.array([target_cat]),dtype=torch.long).cuda())\n",
    "            max_score, max_label = scores.max(1)\n",
    "            if max_label == target_cat:\n",
    "                correct+=1\n",
    "            cum_loss+=loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Train-epoch %d. Iteration %05d, Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "                    (epoch, i + 1, cum_loss / (i + 1), correct / ((i + 1) * batchSize)))\n",
    "            i+=1\n",
    "        train_accuracies.append(correct / len(train_set))\n",
    "        train_losses.append(cum_loss / (i + 1))   \n",
    "\n",
    "   \n",
    "train_model(categories_used,lossFn,batchSize,learningRate,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 1.6, PyTorch 0.4, Keras",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
