{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "res_model = models.resnet50(pretrained=True)\n",
    "print(res_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g01_c01', 'g01_c02', 'g01_c03', 'g01_c04', 'g01_c05', 'g01_c06', 'g02_c01', 'g02_c02', 'g02_c03', 'g02_c04', 'g03_c01', 'g03_c02', 'g03_c03', 'g03_c04', 'g03_c05', 'g03_c06', 'g04_c01', 'g04_c02', 'g04_c03', 'g04_c04', 'g04_c05', 'g04_c06', 'g04_c07', 'g05_c01', 'g05_c02', 'g05_c03', 'g05_c04', 'g05_c05', 'g05_c06', 'g05_c07', 'g06_c01', 'g06_c02', 'g06_c03', 'g06_c04', 'g06_c05', 'g06_c06', 'g06_c07', 'g07_c01', 'g07_c02', 'g07_c03', 'g07_c04', 'g07_c05', 'g07_c06', 'g07_c07', 'g08_c01', 'g08_c02', 'g08_c03', 'g08_c04', 'g08_c05', 'g09_c01', 'g09_c02', 'g09_c03', 'g09_c04', 'g09_c05', 'g09_c06', 'g09_c07', 'g10_c01', 'g10_c02', 'g10_c03', 'g10_c04', 'g10_c05', 'g11_c01', 'g11_c02', 'g11_c03', 'g11_c04', 'g11_c05', 'g12_c01', 'g12_c02', 'g12_c03', 'g12_c04', 'g12_c05', 'g12_c06', 'g13_c01', 'g13_c02', 'g13_c03', 'g13_c04', 'g13_c05', 'g13_c06', 'g14_c01', 'g14_c02', 'g14_c03', 'g14_c04', 'g14_c05', 'g15_c01', 'g15_c02', 'g15_c03', 'g15_c04', 'g15_c05', 'g15_c06', 'g15_c07', 'g16_c01', 'g16_c02', 'g16_c03', 'g16_c04', 'g16_c05', 'g17_c01', 'g17_c02', 'g17_c03', 'g17_c04', 'g17_c05', 'g18_c01', 'g18_c02', 'g18_c03', 'g18_c04', 'g18_c05', 'g19_c01', 'g19_c02', 'g19_c03', 'g19_c04', 'g20_c01', 'g20_c02', 'g20_c03', 'g20_c04', 'g20_c05', 'g20_c06', 'g21_c01', 'g21_c02', 'g21_c03', 'g21_c04', 'g21_c05', 'g22_c01', 'g22_c02', 'g22_c03', 'g22_c04', 'g22_c05', 'g23_c01', 'g23_c02', 'g23_c03', 'g23_c04', 'g23_c05', 'g23_c06', 'g24_c01', 'g24_c02', 'g24_c03', 'g24_c04', 'g24_c05', 'g24_c06', 'g24_c07', 'g25_c01', 'g25_c02', 'g25_c03', 'g25_c04', 'g25_c05', 'g25_c06', 'g25_c07']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('data/data_first_25/ApplyEyeMakeup'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0339, -0.2803, -0.5588, -1.0633, -0.5982, -0.1185, -0.7245,  0.4723,\n",
      "          0.1687, -0.7725, -0.8772, -0.9897, -0.3863, -0.9537, -0.8534, -0.4497,\n",
      "         -0.6492, -0.1997, -0.1648, -0.4842, -1.0847, -0.7866, -1.3034, -0.1153,\n",
      "         -1.0191, -0.7022, -0.8275, -0.6509, -0.5022, -0.4131, -0.7665, -0.8926,\n",
      "         -0.6493, -0.4952, -0.2028, -0.5817,  0.5857, -0.6630, -0.3757,  0.1591,\n",
      "         -0.5846, -0.6555, -0.6937, -0.2647, -0.2696, -0.2190, -0.5557, -0.4581,\n",
      "         -1.1228, -0.7563, -0.2625,  0.3987, -0.2595, -0.3165, -0.1794, -0.9064,\n",
      "         -0.4023, -0.9893, -0.2564,  0.0165,  0.7054,  0.2354, -0.0092,  0.0259,\n",
      "         -0.5421, -0.1671, -0.3316, -0.1988, -0.6164, -0.4905, -1.3046,  0.3017,\n",
      "         -1.3353, -0.5006, -0.8859, -0.8446,  0.1442, -0.3220,  0.4130,  0.0800,\n",
      "         -0.8237, -1.5672,  0.1075, -0.7383, -0.5086, -0.1458,  0.0601,  0.4678,\n",
      "         -0.0493, -0.4882, -0.6295, -0.9816, -1.3854, -0.4129,  0.0985, -1.4554,\n",
      "         -0.3752, -0.6398, -1.1034, -0.3851, -0.8985, -0.6859, -0.7673, -0.3249,\n",
      "         -0.2561, -0.9004, -0.6850, -1.1488, -0.7714, -1.1816, -1.3059, -0.6691,\n",
      "          0.9172,  0.3499,  0.5403, -1.4633, -0.7400, -0.3105,  0.5581, -0.1205,\n",
      "         -0.7305, -0.1907,  0.2468,  0.0809,  0.9194, -0.1681,  0.3339, -1.2033,\n",
      "         -0.9396, -1.1074, -1.0576, -1.1627, -1.0956, -1.4365, -0.4511, -1.0183,\n",
      "         -0.7324, -1.2114, -1.4655, -1.3438, -1.1321, -1.3861, -1.8985, -1.2623,\n",
      "         -0.7469, -0.1798, -0.9186, -1.3940, -1.0991, -1.2244,  0.1613,  1.3019,\n",
      "         -0.6288, -0.3731,  0.0415,  0.5078, -0.1503,  0.1216,  0.0897,  0.2687,\n",
      "          0.2336,  0.4029,  0.2937,  0.7217,  0.1861, -0.2087, -0.2603, -0.4403,\n",
      "          0.4799, -0.1617,  0.0047,  0.7641,  0.2870,  0.2458,  0.1146, -0.4568,\n",
      "          0.0343, -0.1178,  0.4809,  0.4670,  0.3795,  0.1754,  0.5300,  0.2935,\n",
      "          0.6781,  0.6715,  0.6389,  0.4158,  0.2479,  0.6554, -0.2729,  0.3841,\n",
      "          0.4861,  0.6587, -0.5822,  0.8511,  0.1703,  0.2676,  0.0726,  0.6383,\n",
      "          0.1639, -0.0004,  0.2409,  0.5026,  0.1180,  0.1444, -0.0885,  0.4162,\n",
      "          1.1102,  0.5241, -0.2149,  0.5232,  0.1902,  0.0016,  0.2106,  0.2255,\n",
      "          0.1280,  0.1557, -0.1441,  0.3052,  0.3565, -0.0306,  0.0897,  0.5953,\n",
      "          0.3038,  0.5103,  0.2024,  0.7872, -0.4044, -0.1646,  0.0445,  0.5570,\n",
      "          0.2711, -0.2303,  0.6368,  0.6347,  0.6406,  0.3872,  0.5985,  0.1028,\n",
      "          0.3560,  0.0162,  0.5313,  0.3215, -0.1825,  0.3009,  0.2648,  0.0538,\n",
      "          0.4179,  0.0562,  0.5588,  0.8501, -0.4849,  0.6048,  0.8856, -0.5435,\n",
      "          0.5619,  0.2061,  0.1791,  0.1888, -0.1065, -0.2494, -0.1059,  0.2807,\n",
      "          0.5539,  0.6662,  0.3010,  0.4282,  0.1170, -0.6203, -0.6980, -0.7352,\n",
      "         -0.4023,  0.6582, -0.9708, -1.0374, -0.7851, -0.8297, -1.1679, -0.7514,\n",
      "         -0.1809,  0.8438,  0.5942,  0.1489,  0.4369,  0.9852, -0.5133, -0.4122,\n",
      "         -0.6643, -1.4580, -0.9544, -1.1666, -0.1527, -0.8878, -1.0689, -0.8468,\n",
      "         -0.9476, -1.2590, -0.5095, -0.2343, -1.2579, -0.8823, -0.2861, -0.3155,\n",
      "         -1.0827, -0.7941,  0.4006, -0.7442, -1.3354, -0.3283,  0.4408, -0.2144,\n",
      "         -0.2740,  0.3010,  0.5975, -0.5041, -1.0471, -1.2931, -0.9981, -0.4582,\n",
      "         -1.1895, -0.8077, -0.9990, -1.3612, -1.1669, -1.3539, -1.0057,  0.2488,\n",
      "         -0.2194, -0.5853,  0.0561,  0.0419,  0.0432,  0.0375, -0.3930, -0.6554,\n",
      "         -1.2620, -0.0292,  0.3298, -1.0070, -0.2688,  0.5153, -0.3754, -0.8725,\n",
      "         -1.0361,  0.2805, -0.6769, -1.3489, -0.1930, -1.1157, -0.9266, -1.9220,\n",
      "         -1.1524, -0.6532, -0.6760,  0.2611,  1.0484,  0.1191,  0.6028,  0.3199,\n",
      "         -0.2227,  0.2021, -0.1606,  0.0133, -0.3868, -0.2869, -1.2828, -0.4002,\n",
      "         -0.8874, -0.8042, -0.5445, -0.3291, -0.7333,  0.0726, -0.4559, -0.8306,\n",
      "         -1.0902,  0.0852, -0.2098, -0.5067,  0.1622, -0.5386, -0.2321, -0.7579,\n",
      "         -0.8296, -0.5123, -0.8290, -1.1669, -1.1162, -0.3021,  0.0871,  0.1422,\n",
      "         -1.2181, -1.5783, -0.3790,  0.0721, -0.8461, -0.8392,  0.1826,  0.3826,\n",
      "         -0.3868,  0.5766,  0.1005, -1.7681, -1.8077, -0.6956, -0.2870, -0.6100,\n",
      "         -0.4820,  1.2181, -0.5801,  0.1505,  1.3898,  0.5082,  0.4304,  0.8407,\n",
      "         -0.3014,  0.5702,  0.0501,  1.0037,  0.6578,  0.7382, -0.0175,  0.0172,\n",
      "         -0.0469, -1.1144,  0.3770,  1.1499,  1.1717,  0.3157, -0.2589, -0.3569,\n",
      "          0.2878,  0.5853,  0.6513,  0.9729, -0.1702, -0.4334,  0.5432,  0.2279,\n",
      "          1.0053,  0.1314,  0.0231, -0.3397, -0.4281,  0.3636,  0.0290,  1.3017,\n",
      "          0.6853, -0.9012, -0.5149,  0.3244,  0.5544, -0.1072, -0.1483,  0.5492,\n",
      "          1.1110,  1.1753, -0.1199,  0.7578, -0.4776,  0.6926,  1.0162,  2.0084,\n",
      "          0.6901, -0.2587, -1.2484,  0.0816, -0.2876,  1.3146,  0.7926,  0.3730,\n",
      "         -0.1550,  0.4679, -0.2966,  0.1521,  0.0720,  0.3576,  0.6867,  0.4290,\n",
      "          0.1966,  0.0381,  0.0679, -0.8577, -1.3699,  0.0078, -0.3182,  1.0806,\n",
      "          1.3975,  0.6506,  0.3527,  0.6322,  0.2752, -0.9431,  0.9131, -0.9030,\n",
      "         -0.0787, -0.3534, -0.2409,  0.9511, -1.5947,  0.6083,  1.0034,  0.5848,\n",
      "          0.9324,  0.7562,  0.8832,  0.3028,  0.3453,  0.0887, -0.9683, -0.5169,\n",
      "          0.7159,  0.3617,  0.8365,  1.5944,  0.0063, -0.1533,  1.0127,  0.7464,\n",
      "         -0.9459,  0.4325,  0.5545,  1.4628,  0.2432, -1.0037, -0.1533, -0.4951,\n",
      "          0.4571,  0.2400,  0.9198,  0.3952,  0.0766, -0.3941,  0.3293, -0.6031,\n",
      "         -0.4247, -0.7791, -0.3357,  1.0659, -0.8895,  1.3984,  0.8205,  0.3964,\n",
      "          0.3023,  0.9239,  0.3173, -1.8355, -0.9052, -0.2055, -0.2883,  0.1890,\n",
      "          0.9121, -0.1039, -1.1934, -0.6441,  0.2456,  0.5024,  1.0347,  0.7757,\n",
      "          0.0848, -0.0648,  0.6181, -0.2019, -1.1641, -0.6441,  0.3462,  0.9721,\n",
      "          0.3524, -0.6069,  0.8994, -0.0326,  0.9424, -1.2355,  0.8729, -0.1273,\n",
      "         -0.8453,  1.0456,  0.5638,  0.1522,  0.1660, -0.2878,  0.7445,  0.6754,\n",
      "          0.4388,  0.7552, -0.3019,  1.3227,  0.4925,  0.9578, -0.2787,  0.4990,\n",
      "         -0.7973,  0.7635,  0.4042, -0.7565,  1.1628, -0.1939, -0.4338,  0.6470,\n",
      "          2.0600,  0.2300, -0.2189, -0.4528,  0.4397,  0.4325,  1.0136, -0.2192,\n",
      "          0.7408, -0.4241,  0.8154,  0.4348, -0.3640,  0.3278, -0.0363,  0.2418,\n",
      "          0.7966,  0.6615,  1.5865,  0.7318,  0.9959,  0.5810,  0.2997,  0.4340,\n",
      "         -0.0668, -0.8810,  0.8124, -0.1747, -1.0952, -0.0573, -0.0141,  0.7269,\n",
      "          0.6783,  1.0163, -0.1289,  0.5450,  0.9107,  0.6281,  0.9463,  0.3358,\n",
      "         -1.5324,  1.0600,  0.1876,  1.2353,  0.5731, -0.8043,  0.4928,  0.2325,\n",
      "         -0.8183, -1.1964,  1.0698,  0.0422,  0.7667,  0.7128, -0.1282,  0.8140,\n",
      "          0.0521, -0.0519,  0.0028,  0.3767, -0.2294, -0.9154, -0.2578, -1.1149,\n",
      "          0.5766, -0.0219,  1.2263,  0.6574, -0.7504, -0.7224,  0.1244, -0.0027,\n",
      "         -0.2511,  0.6244,  0.9846, -0.8000,  1.4166,  0.8551,  0.9852,  0.1659,\n",
      "          0.6710,  0.6538, -0.4133,  0.4987,  0.6108, -0.9423, -0.3014, -0.8987,\n",
      "         -0.1526, -0.7366, -0.6491,  0.9121,  0.9799,  0.4322, -1.0073,  0.7811,\n",
      "          1.3690,  0.0854, -0.4588,  0.5281,  1.6994,  0.0590, -0.2583,  0.1921,\n",
      "          0.4222, -0.0909, -0.4551,  0.6974,  0.6993,  0.1320,  0.3875,  0.7065,\n",
      "          0.0411, -0.2973,  0.3542, -0.4229,  0.5038, -0.7436, -0.2537,  0.5872,\n",
      "          0.4382,  0.1968,  1.2150,  0.1216, -0.5727,  0.9867, -0.7604, -0.1610,\n",
      "          1.4070, -0.4993,  0.0169,  1.8699, -0.4314,  1.6064, -1.0934,  0.0476,\n",
      "         -0.1299,  1.0532,  0.8409,  0.1174,  0.7917,  0.1058,  0.3280,  0.3173,\n",
      "          0.3411, -0.1631,  0.0983,  0.4174,  0.5084,  1.0312,  0.3502, -0.3407,\n",
      "          0.2768,  0.6024,  0.8239, -0.5200,  0.7126, -0.0023,  1.2089, -0.0255,\n",
      "          0.1473,  0.7308,  0.6201,  0.2858,  1.0930,  0.6451,  0.4407,  0.3971,\n",
      "         -0.1434,  1.1375,  0.5170,  0.1356,  1.1474,  0.4922,  0.7249,  0.5305,\n",
      "          0.4147,  0.2108,  1.2101, -0.6958, -0.8483, -0.7774,  0.7965,  0.7450,\n",
      "          1.3933,  0.2810,  0.6054,  0.8336,  0.4538,  0.1702,  0.5131,  0.7590,\n",
      "          1.2332,  1.0643,  0.1471,  0.2260,  0.8637,  0.6718, -0.6090,  0.4500,\n",
      "         -0.3427,  0.2472, -1.1176, -1.2998,  1.0139,  0.8303,  0.3295,  0.1903,\n",
      "          1.3934,  0.1552, -0.3210,  0.9127, -0.3648,  1.4198, -0.9287, -0.2785,\n",
      "          0.3912, -0.9906,  1.1781,  0.1617, -1.4179, -1.1366,  0.2621,  0.8023,\n",
      "          0.9141, -0.7941,  0.7273,  0.7684,  1.2293, -0.5574,  1.1081,  0.1106,\n",
      "         -0.7654, -0.9010,  0.5370,  0.2103,  1.5390,  1.6241,  1.0755, -0.6747,\n",
      "          1.2401,  0.5300,  0.4959,  0.2378, -0.0350,  1.4246,  0.5320, -0.4287,\n",
      "          0.1120,  0.7258,  1.0687,  1.3856,  1.7532, -0.3680, -0.0833,  0.8630,\n",
      "         -0.8925, -0.3367, -0.1283,  0.6665,  0.4484,  1.1453,  0.5494, -0.1781,\n",
      "         -0.5684,  0.5149,  0.1131, -0.4744,  1.0276, -0.1649,  0.6650, -1.2616,\n",
      "          0.8331, -0.8130, -1.9059,  0.2063,  1.2060, -0.1760, -0.1430,  1.3753,\n",
      "          0.9578, -0.0534,  0.8983,  0.9689,  0.0273,  0.3283, -0.0945, -0.3033,\n",
      "         -0.9601,  0.5323, -0.7210,  0.1592,  0.7661, -0.1544, -0.3699, -0.9321,\n",
      "          0.7871,  0.6378,  1.5903,  1.5595, -0.9143, -0.0679,  1.4354,  0.9179,\n",
      "          0.6926,  0.0751, -0.0568,  1.1216, -0.8923,  0.4930,  1.4623,  1.3364,\n",
      "          0.7595, -0.6943, -1.8413, -0.3958,  0.4038,  0.3109,  0.6325,  0.1140,\n",
      "         -0.2120,  0.9008, -0.6726,  0.4339,  0.0159, -0.8301, -0.8479, -0.5306,\n",
      "         -0.1553,  1.2679,  0.0083,  0.1316,  0.3101, -1.3664,  0.1959, -0.3392,\n",
      "          0.2606,  0.5912,  0.2892,  0.2253, -0.3706, -0.1937,  0.2915,  0.3620,\n",
      "         -0.0216, -0.2745, -0.8341,  0.3103,  0.6349,  0.1484,  0.1753, -0.2212,\n",
      "         -0.0498,  0.1388,  0.8545, -0.3470, -0.0640, -0.1297, -0.1690, -0.6635,\n",
      "          0.1572,  0.1648, -0.2281, -0.4759, -0.7720, -0.1714,  0.6526, -0.1995,\n",
      "          0.9123,  0.0967, -0.1028,  1.0707, -0.2433, -0.3648, -1.4959,  0.5408,\n",
      "         -1.2321,  0.5076,  0.1842, -1.0706, -0.6885, -0.0004,  0.4256, -0.2178,\n",
      "         -0.5906, -0.7093, -1.8422,  1.3575, -0.0261, -0.7111, -0.3027, -0.7792,\n",
      "         -0.7742, -1.7864, -0.5015, -0.0309,  0.4081, -0.4251,  1.0680,  0.8762]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#import imageio\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize(256),  # 1. Resize smallest side to 256.\n",
    "     transforms.CenterCrop(224), # 2. Crop center square of 224x224 pixels.\n",
    "     transforms.ToTensor(), # 3. Convert to pytorch tensor.\n",
    "     transforms.Normalize(mean = [0.485, 0.456, 0.406],  # normalize.\n",
    "                          std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "img_pil = Image.open('data/data_first_25/ApplyEyeMakeup/g01_c01/v_ApplyEyeMakeup_g01_c01_frame0.jpg')\n",
    "\n",
    "# 1. Forward propagate the image through the CNN.\n",
    "# Unsqueeze adds a dummy batch dimension needed to pass through the model.\n",
    "input_img =  test_transform(img_pil).unsqueeze(0)\n",
    "\n",
    "print(res_model(input_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_img_list(cat,d1):\n",
    "    ret = list()\n",
    "    for frame in os.listdir('data/data_first_25/{}/{}'.format(cat,d1)):\n",
    "        img_pil = Image.open('data/data_first_25/{}/{}/{}'.format(cat,d1,frame))\n",
    "        input_img = test_transform(img_pil).unsqueeze(0)\n",
    "        ret.append(input_img)\n",
    "    return ret\n",
    "\n",
    "def createTrainAndValSet(categories,trainPercentage):\n",
    "    category_options = os.listdir('data/data_first_25')\n",
    "    category_names = category_options[:categories]\n",
    "    train_set = []\n",
    "    val_set = []\n",
    "    i=0\n",
    "    for cat in category_names:\n",
    "        for d1 in os.listdir('data/data_first_25/{}'.format(cat)):\n",
    "            r = random.uniform(0,1)\n",
    "            img_list = get_img_list(cat,d1)\n",
    "            if r < trainPercentage:\n",
    "                train_set.append((img_list,i))\n",
    "            else:\n",
    "                val_set.append((img_list,i))\n",
    "        i+=1\n",
    "    return train_set,val_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "categories_used = 5\n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "batchSize = 1\n",
    "learningRate = 1e-2\n",
    "epochs = 1\n",
    "trainPercentage = 1\n",
    "\n",
    "train_set, val_set = createTrainAndValSet(categories_used,trainPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-epoch 0. Iteration 00100, Avg-Loss: 5.7978, Accuracy: 0.1800\n",
      "Train-epoch 0. Iteration 00200, Avg-Loss: 4.8785, Accuracy: 0.1900\n",
      "Train-epoch 0. Iteration 00300, Avg-Loss: 4.3643, Accuracy: 0.2167\n",
      "Train-epoch 0. Iteration 00400, Avg-Loss: 4.2850, Accuracy: 0.2000\n",
      "Train-epoch 0. Iteration 00500, Avg-Loss: 4.3437, Accuracy: 0.2060\n",
      "Train-epoch 0. Iteration 00600, Avg-Loss: 4.4172, Accuracy: 0.2083\n",
      "Train-epoch 1. Iteration 00100, Avg-Loss: 4.5869, Accuracy: 0.2300\n",
      "Train-epoch 1. Iteration 00200, Avg-Loss: 4.2170, Accuracy: 0.2200\n",
      "Train-epoch 1. Iteration 00300, Avg-Loss: 4.1375, Accuracy: 0.2433\n",
      "Train-epoch 1. Iteration 00400, Avg-Loss: 4.2230, Accuracy: 0.2350\n",
      "Train-epoch 1. Iteration 00500, Avg-Loss: 4.4975, Accuracy: 0.2320\n",
      "Train-epoch 1. Iteration 00600, Avg-Loss: 4.4942, Accuracy: 0.2400\n",
      "Train-epoch 2. Iteration 00100, Avg-Loss: 3.2939, Accuracy: 0.2800\n",
      "Train-epoch 2. Iteration 00200, Avg-Loss: 3.2555, Accuracy: 0.2300\n",
      "Train-epoch 2. Iteration 00300, Avg-Loss: 3.8226, Accuracy: 0.2267\n",
      "Train-epoch 2. Iteration 00400, Avg-Loss: 3.8390, Accuracy: 0.2300\n",
      "Train-epoch 2. Iteration 00500, Avg-Loss: 3.7522, Accuracy: 0.2440\n",
      "Train-epoch 2. Iteration 00600, Avg-Loss: 4.0925, Accuracy: 0.2400\n",
      "Train-epoch 3. Iteration 00100, Avg-Loss: 3.3729, Accuracy: 0.2600\n",
      "Train-epoch 3. Iteration 00200, Avg-Loss: 2.8364, Accuracy: 0.3200\n",
      "Train-epoch 3. Iteration 00300, Avg-Loss: 2.9017, Accuracy: 0.3200\n",
      "Train-epoch 3. Iteration 00400, Avg-Loss: 2.8826, Accuracy: 0.3175\n",
      "Train-epoch 3. Iteration 00500, Avg-Loss: 2.9910, Accuracy: 0.3120\n",
      "Train-epoch 3. Iteration 00600, Avg-Loss: 2.8910, Accuracy: 0.3150\n",
      "Train-epoch 4. Iteration 00100, Avg-Loss: 3.8776, Accuracy: 0.2900\n",
      "Train-epoch 4. Iteration 00200, Avg-Loss: 3.9966, Accuracy: 0.3400\n",
      "Train-epoch 4. Iteration 00300, Avg-Loss: 4.0391, Accuracy: 0.3067\n",
      "Train-epoch 4. Iteration 00400, Avg-Loss: 3.9903, Accuracy: 0.3025\n",
      "Train-epoch 4. Iteration 00500, Avg-Loss: 4.0164, Accuracy: 0.3000\n",
      "Train-epoch 4. Iteration 00600, Avg-Loss: 4.0075, Accuracy: 0.3033\n",
      "Train-epoch 5. Iteration 00100, Avg-Loss: 2.7517, Accuracy: 0.3400\n",
      "Train-epoch 5. Iteration 00200, Avg-Loss: 2.6504, Accuracy: 0.3650\n",
      "Train-epoch 5. Iteration 00300, Avg-Loss: 3.1449, Accuracy: 0.3233\n",
      "Train-epoch 5. Iteration 00400, Avg-Loss: 3.2231, Accuracy: 0.3200\n",
      "Train-epoch 5. Iteration 00500, Avg-Loss: 3.0739, Accuracy: 0.3140\n",
      "Train-epoch 5. Iteration 00600, Avg-Loss: 3.4105, Accuracy: 0.3067\n",
      "Train-epoch 6. Iteration 00100, Avg-Loss: 2.8103, Accuracy: 0.3600\n",
      "Train-epoch 6. Iteration 00200, Avg-Loss: 2.7612, Accuracy: 0.3250\n",
      "Train-epoch 6. Iteration 00300, Avg-Loss: 2.6953, Accuracy: 0.3400\n",
      "Train-epoch 6. Iteration 00400, Avg-Loss: 2.7902, Accuracy: 0.3225\n",
      "Train-epoch 6. Iteration 00500, Avg-Loss: 2.7377, Accuracy: 0.3300\n",
      "Train-epoch 6. Iteration 00600, Avg-Loss: 2.7722, Accuracy: 0.3317\n",
      "Train-epoch 7. Iteration 00100, Avg-Loss: 2.7147, Accuracy: 0.3100\n",
      "Train-epoch 7. Iteration 00200, Avg-Loss: 3.2318, Accuracy: 0.3100\n",
      "Train-epoch 7. Iteration 00300, Avg-Loss: 3.4036, Accuracy: 0.3400\n",
      "Train-epoch 7. Iteration 00400, Avg-Loss: 3.1547, Accuracy: 0.3525\n",
      "Train-epoch 7. Iteration 00500, Avg-Loss: 2.8246, Accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "learningRate = 5e-3\n",
    "epochs = 10\n",
    "\n",
    "train_accuracies = []; val_accuracies = []\n",
    "train_losses = []; val_losses = []\n",
    "\n",
    "\n",
    "def train_model(categories,lossFn,batchSize,learningRate,epochs,trainPercentage):\n",
    "    model = models.resnet50(pretrained=True).cuda()\n",
    "    lossFn = lossFn.cuda()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "#     for param in model.fc.parameters():\n",
    "#         param.requires_grad = True\n",
    "    model.fc = nn.Linear(in_features=2048,out_features=categories).cuda()\n",
    "    model.fc.requires_grad = True\n",
    "    optimizer = optim.Adam(model.fc.parameters(),lr=learningRate,weight_decay=1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        shuffle(train_set)\n",
    "        correct = 0\n",
    "        cum_loss = 0\n",
    "        \n",
    "        model.train()\n",
    "        i=0\n",
    "        for video in train_set:\n",
    "            frame_list,target_cat = video\n",
    "            scores = torch.tensor(np.zeros((1,categories)),dtype=torch.float).cuda()\n",
    "#             for frame in frame_list:\n",
    "#                 frame = frame.cuda()\n",
    "#                 frame_scores = model(frame)\n",
    "#                 scores += frame_scores\n",
    "#             scores/=len(frame_list)\n",
    "            scores = model(frame_list[0].cuda())\n",
    "            loss = lossFn(scores,torch.tensor(np.array([target_cat]),dtype=torch.long).cuda())\n",
    "#             print(scores)\n",
    "#             print(target_cat)\n",
    "#             print(loss)\n",
    "            max_score, max_label = scores.max(1)\n",
    "            if max_label == target_cat:\n",
    "                correct+=1\n",
    "            cum_loss+=loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Train-epoch %d. Iteration %05d, Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "                    (epoch, i + 1, cum_loss / (i + 1), correct / ((i + 1) * batchSize)))\n",
    "            i+=1\n",
    "        train_accuracies.append(correct / len(train_set))\n",
    "        train_losses.append(cum_loss / (i + 1))   \n",
    "\n",
    "   \n",
    "train_model(categories_used,lossFn,batchSize,learningRate,epochs,trainPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
