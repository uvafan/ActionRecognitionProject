{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize(256),  # 1. Resize smallest side to 256.\n",
    "     transforms.CenterCrop(224), # 2. Crop center square of 224x224 pixels.\n",
    "     transforms.ToTensor(), # 3. Convert to pytorch tensor.\n",
    "     transforms.Normalize(mean = [0.485, 0.456, 0.406],  # normalize.\n",
    "                          std = [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(cat,d1):\n",
    "    ret = list()\n",
    "    for frame in os.listdir('data/data_first_25/{}/{}'.format(cat,d1)):\n",
    "        img_pil = Image.open('data/data_first_25/{}/{}/{}'.format(cat,d1,frame))\n",
    "        input_img = test_transform(img_pil).unsqueeze(0)\n",
    "        ret.append(input_img)\n",
    "    return ret\n",
    "\n",
    "def createTrainAndValSet(categories,trainPercentage):\n",
    "    category_options = sorted(os.listdir('data/data_first_25'))\n",
    "    category_names = category_options[:categories]\n",
    "    train_set = []\n",
    "    val_set = []\n",
    "    i=0\n",
    "    for cat in category_names:\n",
    "        print(cat)\n",
    "        for d1 in os.listdir('data/data_first_25/{}'.format(cat)):\n",
    "            img_list = get_img_list(cat,d1)\n",
    "            if int(d1[1:3]) <= trainPercentage * 25:\n",
    "                train_set.append((img_list,i))\n",
    "            else:\n",
    "                val_set.append((img_list,i))\n",
    "        i+=1\n",
    "    return train_set,val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageModel(nn.Module):\n",
    "    def __init__(self, output_size=5):\n",
    "        super(AverageModel, self).__init__()\n",
    "\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
    "        self.output_size = output_size\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.lstm = nn.LSTM(resnet.fc.in_features, resnet.fc.in_features)\n",
    "        self.hidden = (Variable(torch.randn(1, 1, resnet.fc.in_features).cuda()), Variable(\n",
    "torch.randn((1, 1, resnet.fc.in_features)).cuda())) \n",
    "        self.fc1 = nn.Linear(resnet.fc.in_features, output_size)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "    def forward(self, x_3d):        \n",
    "        x = self.resnet(x_3d.squeeze())  # ResNet\n",
    "        \n",
    "#       Rearranging layers for LSTM so it is in the format: [sequence length, batch size, input size]\n",
    "        x = x.transpose(1, 2)[:, :, :, 0]\n",
    "        x, self.hidden = self.lstm(x, self.hidden)\n",
    "        \n",
    "#       Detach hidden layers so we don't run out of memory\n",
    "        self.hidden[0].detach_()\n",
    "        self.hidden[1].detach_()\n",
    "\n",
    "        # FC layers\n",
    "#       Using only the last output layer, because this is an LSTM\n",
    "        x = self.fc1(x[-1, :, :])\n",
    "        x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "train_accuracies = []; train_losses = [];\n",
    "val_accuracies = []; val_losses = [];\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, epochs):\n",
    "    model = model.cuda()\n",
    "    loss_fn = loss_fn.cuda()\n",
    "    batchSize = 1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        cum_loss = 0\n",
    "\n",
    "        i = 0\n",
    "        model.train()\n",
    "        shuffle(train_set)\n",
    "        for video in train_set:\n",
    "            frame_list, target_cat = video\n",
    "            frame_list = torch.stack(frame_list, dim=0).transpose(0, 1).cuda()\n",
    "            scores = model(frame_list)\n",
    "            \n",
    "            \n",
    "            loss = loss_fn(scores, torch.tensor(np.array([target_cat]),dtype=torch.long).cuda())\n",
    "            max_score, max_label = scores.max(1)\n",
    "            if max_label == target_cat:\n",
    "                correct+=1\n",
    "            cum_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Train-epoch %d. Iteration %05d, Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "                    (epoch, i + 1, cum_loss / (i + 1), correct / ((i + 1) * batchSize)))\n",
    "            i += 1\n",
    "            \n",
    "        train_accuracies.append(correct / len(train_set))\n",
    "        train_losses.append(cum_loss / (i + 1))   \n",
    "        \n",
    "        i = 0\n",
    "        correct = 0\n",
    "        cum_loss = 0\n",
    "        model.eval()\n",
    "        shuffle(val_set)\n",
    "        for video in val_set:\n",
    "            frame_list, target_cat = video\n",
    "            frame_list = torch.stack(frame_list, dim=0).transpose(0, 1).cuda()\n",
    "            scores = model(frame_list)\n",
    "            \n",
    "            loss = loss_fn(scores, torch.tensor(np.array([target_cat]),dtype=torch.long).cuda())\n",
    "            max_score, max_label = scores.max(1)\n",
    "            if max_label == target_cat:\n",
    "                correct+=1\n",
    "            cum_loss += loss.item()\n",
    "            \n",
    "            i += 1\n",
    "        print('Validation-epoch %d. Iteration %05d, Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "               (epoch, i + 1, cum_loss / (i + 1), correct / len(val_set)))\n",
    "        \n",
    "        val_accuracies.append(correct / len(val_set))\n",
    "        val_losses.append(cum_loss / (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplyEyeMakeup\n",
      "ApplyLipstick\n",
      "Archery\n",
      "BabyCrawling\n",
      "BalanceBeam\n",
      "BandMarching\n",
      "BaseballPitch\n",
      "Basketball\n",
      "BasketballDunk\n",
      "BenchPress\n"
     ]
    }
   ],
   "source": [
    "categories = 10\n",
    "\n",
    "train_set, val_set = createTrainAndValSet(categories, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-epoch 0. Iteration 00100, Avg-Loss: 2.3110, Accuracy: 0.1400\n",
      "Train-epoch 0. Iteration 00200, Avg-Loss: 2.3181, Accuracy: 0.1400\n",
      "Train-epoch 0. Iteration 00300, Avg-Loss: 2.3271, Accuracy: 0.1233\n",
      "Train-epoch 0. Iteration 00400, Avg-Loss: 2.3320, Accuracy: 0.1125\n",
      "Train-epoch 0. Iteration 00500, Avg-Loss: 2.3386, Accuracy: 0.1000\n",
      "Train-epoch 0. Iteration 00600, Avg-Loss: 2.3407, Accuracy: 0.0967\n",
      "Train-epoch 0. Iteration 00700, Avg-Loss: 2.3409, Accuracy: 0.0971\n",
      "Train-epoch 0. Iteration 00800, Avg-Loss: 2.3402, Accuracy: 0.0963\n",
      "Train-epoch 0. Iteration 00900, Avg-Loss: 2.3382, Accuracy: 0.0911\n",
      "Validation-epoch 0. Iteration 00387, Avg-Loss: 2.3046, Accuracy: 0.1218\n",
      "Train-epoch 1. Iteration 00100, Avg-Loss: 2.2766, Accuracy: 0.1100\n",
      "Train-epoch 1. Iteration 00200, Avg-Loss: 2.2713, Accuracy: 0.1200\n",
      "Train-epoch 1. Iteration 00300, Avg-Loss: 2.2827, Accuracy: 0.1133\n",
      "Train-epoch 1. Iteration 00400, Avg-Loss: 2.2856, Accuracy: 0.1300\n",
      "Train-epoch 1. Iteration 00500, Avg-Loss: 2.2809, Accuracy: 0.1320\n",
      "Train-epoch 1. Iteration 00600, Avg-Loss: 2.2798, Accuracy: 0.1333\n",
      "Train-epoch 1. Iteration 00700, Avg-Loss: 2.2840, Accuracy: 0.1229\n",
      "Train-epoch 1. Iteration 00800, Avg-Loss: 2.2792, Accuracy: 0.1325\n",
      "Train-epoch 1. Iteration 00900, Avg-Loss: 2.2797, Accuracy: 0.1311\n",
      "Validation-epoch 1. Iteration 00387, Avg-Loss: 2.3024, Accuracy: 0.1477\n",
      "Train-epoch 2. Iteration 00100, Avg-Loss: 2.2085, Accuracy: 0.1900\n",
      "Train-epoch 2. Iteration 00200, Avg-Loss: 2.2206, Accuracy: 0.2000\n",
      "Train-epoch 2. Iteration 00300, Avg-Loss: 2.2193, Accuracy: 0.2100\n",
      "Train-epoch 2. Iteration 00400, Avg-Loss: 2.2146, Accuracy: 0.2150\n",
      "Train-epoch 2. Iteration 00500, Avg-Loss: 2.2111, Accuracy: 0.2200\n",
      "Train-epoch 2. Iteration 00600, Avg-Loss: 2.2118, Accuracy: 0.2283\n",
      "Train-epoch 2. Iteration 00700, Avg-Loss: 2.2084, Accuracy: 0.2314\n",
      "Train-epoch 2. Iteration 00800, Avg-Loss: 2.2061, Accuracy: 0.2325\n",
      "Train-epoch 2. Iteration 00900, Avg-Loss: 2.1997, Accuracy: 0.2322\n",
      "Validation-epoch 2. Iteration 00387, Avg-Loss: 2.3217, Accuracy: 0.1088\n",
      "Train-epoch 3. Iteration 00100, Avg-Loss: 2.0219, Accuracy: 0.3200\n",
      "Train-epoch 3. Iteration 00200, Avg-Loss: 2.0147, Accuracy: 0.3450\n",
      "Train-epoch 3. Iteration 00300, Avg-Loss: 1.9979, Accuracy: 0.3567\n",
      "Train-epoch 3. Iteration 00400, Avg-Loss: 1.9953, Accuracy: 0.3775\n",
      "Train-epoch 3. Iteration 00500, Avg-Loss: 1.9827, Accuracy: 0.3880\n",
      "Train-epoch 3. Iteration 00600, Avg-Loss: 1.9776, Accuracy: 0.3983\n",
      "Train-epoch 3. Iteration 00700, Avg-Loss: 1.9646, Accuracy: 0.4071\n",
      "Train-epoch 3. Iteration 00800, Avg-Loss: 1.9505, Accuracy: 0.4100\n",
      "Train-epoch 3. Iteration 00900, Avg-Loss: 1.9460, Accuracy: 0.4144\n",
      "Validation-epoch 3. Iteration 00387, Avg-Loss: 2.3398, Accuracy: 0.1399\n",
      "Train-epoch 4. Iteration 00100, Avg-Loss: 1.4608, Accuracy: 0.5900\n",
      "Train-epoch 4. Iteration 00200, Avg-Loss: 1.4858, Accuracy: 0.6200\n",
      "Train-epoch 4. Iteration 00300, Avg-Loss: 1.4425, Accuracy: 0.6267\n",
      "Train-epoch 4. Iteration 00400, Avg-Loss: 1.4396, Accuracy: 0.6150\n",
      "Train-epoch 4. Iteration 00500, Avg-Loss: 1.4389, Accuracy: 0.5980\n",
      "Train-epoch 4. Iteration 00600, Avg-Loss: 1.4206, Accuracy: 0.6100\n",
      "Train-epoch 4. Iteration 00700, Avg-Loss: 1.4373, Accuracy: 0.5971\n",
      "Train-epoch 4. Iteration 00800, Avg-Loss: 1.4426, Accuracy: 0.5925\n",
      "Train-epoch 4. Iteration 00900, Avg-Loss: 1.4661, Accuracy: 0.5756\n",
      "Validation-epoch 4. Iteration 00387, Avg-Loss: 2.7615, Accuracy: 0.1114\n",
      "Train-epoch 5. Iteration 00100, Avg-Loss: 1.1492, Accuracy: 0.6500\n",
      "Train-epoch 5. Iteration 00200, Avg-Loss: 1.1464, Accuracy: 0.6350\n",
      "Train-epoch 5. Iteration 00300, Avg-Loss: 1.1348, Accuracy: 0.6400\n",
      "Train-epoch 5. Iteration 00400, Avg-Loss: 1.0849, Accuracy: 0.6475\n",
      "Train-epoch 5. Iteration 00500, Avg-Loss: 1.0629, Accuracy: 0.6600\n",
      "Train-epoch 5. Iteration 00600, Avg-Loss: 1.0727, Accuracy: 0.6583\n",
      "Train-epoch 5. Iteration 00700, Avg-Loss: 1.0847, Accuracy: 0.6514\n",
      "Train-epoch 5. Iteration 00800, Avg-Loss: 1.1369, Accuracy: 0.6250\n",
      "Train-epoch 5. Iteration 00900, Avg-Loss: 1.1589, Accuracy: 0.6189\n",
      "Validation-epoch 5. Iteration 00387, Avg-Loss: 2.8609, Accuracy: 0.1114\n",
      "Train-epoch 6. Iteration 00100, Avg-Loss: 1.2020, Accuracy: 0.5600\n",
      "Train-epoch 6. Iteration 00200, Avg-Loss: 1.0427, Accuracy: 0.6150\n",
      "Train-epoch 6. Iteration 00300, Avg-Loss: 0.9439, Accuracy: 0.6533\n",
      "Train-epoch 6. Iteration 00400, Avg-Loss: 0.9470, Accuracy: 0.6625\n",
      "Train-epoch 6. Iteration 00500, Avg-Loss: 0.9602, Accuracy: 0.6520\n",
      "Train-epoch 6. Iteration 00600, Avg-Loss: 0.9437, Accuracy: 0.6617\n",
      "Train-epoch 6. Iteration 00700, Avg-Loss: 0.9370, Accuracy: 0.6657\n",
      "Train-epoch 6. Iteration 00800, Avg-Loss: 0.9498, Accuracy: 0.6637\n",
      "Train-epoch 6. Iteration 00900, Avg-Loss: 0.9537, Accuracy: 0.6667\n",
      "Validation-epoch 6. Iteration 00387, Avg-Loss: 3.5515, Accuracy: 0.1813\n",
      "Train-epoch 7. Iteration 00100, Avg-Loss: 0.7337, Accuracy: 0.6900\n",
      "Train-epoch 7. Iteration 00200, Avg-Loss: 0.6589, Accuracy: 0.7450\n",
      "Train-epoch 7. Iteration 00300, Avg-Loss: 0.6604, Accuracy: 0.7533\n",
      "Train-epoch 7. Iteration 00400, Avg-Loss: 0.6674, Accuracy: 0.7525\n",
      "Train-epoch 7. Iteration 00500, Avg-Loss: 0.6866, Accuracy: 0.7420\n",
      "Train-epoch 7. Iteration 00600, Avg-Loss: 0.7125, Accuracy: 0.7367\n",
      "Train-epoch 7. Iteration 00700, Avg-Loss: 0.6965, Accuracy: 0.7400\n",
      "Train-epoch 7. Iteration 00800, Avg-Loss: 0.6797, Accuracy: 0.7425\n",
      "Train-epoch 7. Iteration 00900, Avg-Loss: 0.6748, Accuracy: 0.7444\n",
      "Validation-epoch 7. Iteration 00387, Avg-Loss: 3.7921, Accuracy: 0.1554\n",
      "Train-epoch 8. Iteration 00100, Avg-Loss: 0.4604, Accuracy: 0.7800\n",
      "Train-epoch 8. Iteration 00200, Avg-Loss: 0.4007, Accuracy: 0.8200\n",
      "Train-epoch 8. Iteration 00300, Avg-Loss: 0.4147, Accuracy: 0.8200\n",
      "Train-epoch 8. Iteration 00400, Avg-Loss: 0.4253, Accuracy: 0.8200\n",
      "Train-epoch 8. Iteration 00500, Avg-Loss: 0.4119, Accuracy: 0.8300\n",
      "Train-epoch 8. Iteration 00600, Avg-Loss: 0.4235, Accuracy: 0.8267\n",
      "Train-epoch 8. Iteration 00700, Avg-Loss: 0.4354, Accuracy: 0.8186\n",
      "Train-epoch 8. Iteration 00800, Avg-Loss: 0.4213, Accuracy: 0.8213\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "\n",
    "my_model = AverageModel(output_size=categories)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(my_model.parameters(), lr=learning_rate)\n",
    "epochs = 20\n",
    "\n",
    "train_model(my_model, loss_fn, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(val_losses, 'bo-', label = 'val-loss')\n",
    "plt.plot(train_losses, 'ro-', label = 'train-loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation', 'training'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, 'bo-', label = 'val-acc')\n",
    "plt.plot(train_accuracies, 'ro-', label = 'train-acc')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation', 'training'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 1.6, PyTorch 0.4, Keras",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
