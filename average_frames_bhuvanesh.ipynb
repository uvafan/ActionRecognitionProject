{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import torch\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize(256),  # 1. Resize smallest side to 256.\n",
    "     transforms.CenterCrop(224), # 2. Crop center square of 224x224 pixels.\n",
    "     transforms.ToTensor(), # 3. Convert to pytorch tensor.\n",
    "     transforms.Normalize(mean = [0.485, 0.456, 0.406],  # normalize.\n",
    "                          std = [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(cat,d1):\n",
    "    ret = list()\n",
    "    for frame in os.listdir('data/data_first_25/{}/{}'.format(cat,d1)):\n",
    "        img_pil = Image.open('data/data_first_25/{}/{}/{}'.format(cat,d1,frame))\n",
    "        input_img = test_transform(img_pil).unsqueeze(0)\n",
    "        ret.append(input_img)\n",
    "    return ret\n",
    "\n",
    "def createTrainAndValSet(categories,trainPercentage):\n",
    "    category_options = os.listdir('data/data_first_25')\n",
    "    category_names = category_options[:categories]\n",
    "    train_set = []\n",
    "    val_set = []\n",
    "    i=0\n",
    "    for cat in category_names:\n",
    "        for d1 in os.listdir('data/data_first_25/{}'.format(cat)):\n",
    "            r = random.uniform(0,1)\n",
    "            img_list = get_img_list(cat,d1)\n",
    "            if r < trainPercentage:\n",
    "                train_set.append((img_list,i))\n",
    "            else:\n",
    "                val_set.append((img_list,i))\n",
    "        i+=1\n",
    "    return train_set,val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageModel(nn.Module):\n",
    "    def __init__(self, output_size=5):\n",
    "        super(AverageModel, self).__init__()\n",
    "\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
    "        self.output_size = output_size\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(resnet.fc.in_features, output_size)\n",
    "        \n",
    "    def forward(self, x_3d):\n",
    "        result = torch.zeros((1,self.output_size)).cuda()\n",
    "        for t in range(x_3d.size(1)):\n",
    "            with torch.no_grad():\n",
    "                x = self.resnet(x_3d[:, t, :, :, :])  # ResNet\n",
    "                x = x.view(x.size(0), -1)             # flatten output of conv\n",
    "\n",
    "            # FC layers\n",
    "            x = self.fc1(x)\n",
    "          \n",
    "            result += x\n",
    "        result /= x_3d.size(1)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []; train_losses = [];\n",
    "val_accuracies = []; val_losses = [];\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, epochs):\n",
    "    model = model.cuda()\n",
    "    loss_fn = loss_fn.cuda()\n",
    "    batchSize = 1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        cum_loss = 0\n",
    "\n",
    "        i = 0\n",
    "        model.train()\n",
    "        shuffle(train_set)\n",
    "        for video in train_set:\n",
    "            frame_list, target_cat = video\n",
    "            frame_list = torch.stack(frame_list, dim=0).transpose(0, 1).cuda()\n",
    "            scores = model(frame_list)\n",
    "            \n",
    "            loss = loss_fn(scores, torch.tensor(np.array([target_cat]),dtype=torch.long).cuda())\n",
    "            max_score, max_label = scores.max(1)\n",
    "            if max_label == target_cat:\n",
    "                correct+=1\n",
    "            cum_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Train-epoch %d. Iteration %05d, Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "                    (epoch, i + 1, cum_loss / (i + 1), correct / ((i + 1) * batchSize)))\n",
    "            i += 1\n",
    "            \n",
    "        train_accuracies.append(correct / len(train_set))\n",
    "        train_losses.append(cum_loss / (i + 1))   \n",
    "        \n",
    "        i = 0\n",
    "        correct = 0\n",
    "        cum_loss = 0\n",
    "        model.eval()\n",
    "        for video in val_set:\n",
    "            frame_list, target_cat = video\n",
    "            frame_list = torch.stack(frame_list, dim=0).transpose(0, 1).cuda()\n",
    "            scores = model(frame_list)\n",
    "            \n",
    "            loss = loss_fn(scores, torch.tensor(np.array([target_cat]),dtype=torch.long).cuda())\n",
    "            max_score, max_label = scores.max(1)\n",
    "            if max_label == target_cat:\n",
    "                correct+=1\n",
    "            cum_loss += loss.item()\n",
    "            \n",
    "            i += 1\n",
    "        print('Validation-epoch %d. Iteration %05d, Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "               (epoch, i + 1, cum_loss / (i + 1), correct / len(val_set)))\n",
    "        \n",
    "        val_accuracies.append(correct / len(val_set))\n",
    "        val_losses.append(cum_loss / (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = 15\n",
    "\n",
    "train_set, val_set = createTrainAndValSet(categories, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-epoch 0. Iteration 00100, Avg-Loss: 9.8029, Accuracy: 0.0900\n",
      "Train-epoch 0. Iteration 00200, Avg-Loss: 8.7097, Accuracy: 0.0750\n",
      "Train-epoch 0. Iteration 00300, Avg-Loss: 9.0822, Accuracy: 0.0867\n",
      "Train-epoch 0. Iteration 00400, Avg-Loss: 8.8617, Accuracy: 0.0775\n",
      "Train-epoch 0. Iteration 00500, Avg-Loss: 8.8387, Accuracy: 0.0780\n",
      "Train-epoch 0. Iteration 00600, Avg-Loss: 8.7142, Accuracy: 0.0750\n",
      "Train-epoch 0. Iteration 00700, Avg-Loss: 8.4384, Accuracy: 0.0786\n",
      "Train-epoch 0. Iteration 00800, Avg-Loss: 8.4210, Accuracy: 0.0737\n",
      "Train-epoch 0. Iteration 00900, Avg-Loss: 8.4473, Accuracy: 0.0767\n",
      "Train-epoch 0. Iteration 01000, Avg-Loss: 8.4261, Accuracy: 0.0730\n",
      "Train-epoch 0. Iteration 01100, Avg-Loss: 8.4531, Accuracy: 0.0727\n",
      "Train-epoch 0. Iteration 01200, Avg-Loss: 8.5309, Accuracy: 0.0717\n",
      "Train-epoch 0. Iteration 01300, Avg-Loss: 8.5403, Accuracy: 0.0708\n",
      "Train-epoch 0. Iteration 01400, Avg-Loss: 8.5726, Accuracy: 0.0743\n",
      "Train-epoch 0. Iteration 01500, Avg-Loss: 8.4987, Accuracy: 0.0753\n",
      "Train-epoch 0. Iteration 01600, Avg-Loss: 8.4576, Accuracy: 0.0781\n",
      "Validation-epoch 0. Iteration 00426, Avg-Loss: 5.6462, Accuracy: 0.1459\n",
      "Train-epoch 1. Iteration 00100, Avg-Loss: 7.6735, Accuracy: 0.0700\n",
      "Train-epoch 1. Iteration 00200, Avg-Loss: 7.9007, Accuracy: 0.0600\n",
      "Train-epoch 1. Iteration 00300, Avg-Loss: 7.6840, Accuracy: 0.0733\n",
      "Train-epoch 1. Iteration 00400, Avg-Loss: 7.8700, Accuracy: 0.0775\n",
      "Train-epoch 1. Iteration 00500, Avg-Loss: 7.9239, Accuracy: 0.0820\n",
      "Train-epoch 1. Iteration 00600, Avg-Loss: 7.8435, Accuracy: 0.0850\n",
      "Train-epoch 1. Iteration 00700, Avg-Loss: 7.8156, Accuracy: 0.0843\n",
      "Train-epoch 1. Iteration 00800, Avg-Loss: 7.7494, Accuracy: 0.0875\n",
      "Train-epoch 1. Iteration 00900, Avg-Loss: 7.7123, Accuracy: 0.0911\n",
      "Train-epoch 1. Iteration 01000, Avg-Loss: 7.8139, Accuracy: 0.0890\n",
      "Train-epoch 1. Iteration 01100, Avg-Loss: 7.8503, Accuracy: 0.0909\n",
      "Train-epoch 1. Iteration 01200, Avg-Loss: 7.8915, Accuracy: 0.0883\n",
      "Train-epoch 1. Iteration 01300, Avg-Loss: 7.8763, Accuracy: 0.0877\n",
      "Train-epoch 1. Iteration 01400, Avg-Loss: 7.9003, Accuracy: 0.0879\n",
      "Train-epoch 1. Iteration 01500, Avg-Loss: 7.8959, Accuracy: 0.0900\n",
      "Train-epoch 1. Iteration 01600, Avg-Loss: 7.8761, Accuracy: 0.0919\n",
      "Validation-epoch 1. Iteration 00426, Avg-Loss: 5.4095, Accuracy: 0.3318\n",
      "Train-epoch 2. Iteration 00100, Avg-Loss: 8.4332, Accuracy: 0.0600\n",
      "Train-epoch 2. Iteration 00200, Avg-Loss: 7.8405, Accuracy: 0.0850\n",
      "Train-epoch 2. Iteration 00300, Avg-Loss: 7.9258, Accuracy: 0.0900\n",
      "Train-epoch 2. Iteration 00400, Avg-Loss: 7.4990, Accuracy: 0.0975\n",
      "Train-epoch 2. Iteration 00500, Avg-Loss: 7.4628, Accuracy: 0.1040\n",
      "Train-epoch 2. Iteration 00600, Avg-Loss: 7.3867, Accuracy: 0.1117\n",
      "Train-epoch 2. Iteration 00700, Avg-Loss: 7.3218, Accuracy: 0.1143\n",
      "Train-epoch 2. Iteration 00800, Avg-Loss: 7.2972, Accuracy: 0.1212\n",
      "Train-epoch 2. Iteration 00900, Avg-Loss: 7.4539, Accuracy: 0.1156\n",
      "Train-epoch 2. Iteration 01000, Avg-Loss: 7.4393, Accuracy: 0.1160\n",
      "Train-epoch 2. Iteration 01100, Avg-Loss: 7.3738, Accuracy: 0.1145\n",
      "Train-epoch 2. Iteration 01200, Avg-Loss: 7.4810, Accuracy: 0.1142\n",
      "Train-epoch 2. Iteration 01300, Avg-Loss: 7.3791, Accuracy: 0.1131\n",
      "Train-epoch 2. Iteration 01400, Avg-Loss: 7.3363, Accuracy: 0.1136\n",
      "Train-epoch 2. Iteration 01500, Avg-Loss: 7.3234, Accuracy: 0.1120\n",
      "Train-epoch 2. Iteration 01600, Avg-Loss: 7.2933, Accuracy: 0.1087\n",
      "Validation-epoch 2. Iteration 00426, Avg-Loss: 5.8028, Accuracy: 0.2894\n",
      "Train-epoch 3. Iteration 00100, Avg-Loss: 7.0389, Accuracy: 0.1800\n",
      "Train-epoch 3. Iteration 00200, Avg-Loss: 7.2326, Accuracy: 0.1900\n",
      "Train-epoch 3. Iteration 00300, Avg-Loss: 7.3873, Accuracy: 0.1533\n",
      "Train-epoch 3. Iteration 00400, Avg-Loss: 7.3682, Accuracy: 0.1575\n",
      "Train-epoch 3. Iteration 00500, Avg-Loss: 7.2040, Accuracy: 0.1500\n",
      "Train-epoch 3. Iteration 00600, Avg-Loss: 7.0384, Accuracy: 0.1383\n",
      "Train-epoch 3. Iteration 00700, Avg-Loss: 6.8836, Accuracy: 0.1386\n",
      "Train-epoch 3. Iteration 00800, Avg-Loss: 6.9705, Accuracy: 0.1400\n",
      "Train-epoch 3. Iteration 00900, Avg-Loss: 7.2077, Accuracy: 0.1367\n",
      "Train-epoch 3. Iteration 01000, Avg-Loss: 7.2506, Accuracy: 0.1340\n",
      "Train-epoch 3. Iteration 01100, Avg-Loss: 7.2136, Accuracy: 0.1300\n",
      "Train-epoch 3. Iteration 01200, Avg-Loss: 7.0565, Accuracy: 0.1375\n",
      "Train-epoch 3. Iteration 01300, Avg-Loss: 6.9907, Accuracy: 0.1385\n",
      "Train-epoch 3. Iteration 01400, Avg-Loss: 7.0578, Accuracy: 0.1421\n",
      "Train-epoch 3. Iteration 01500, Avg-Loss: 7.0296, Accuracy: 0.1420\n",
      "Train-epoch 3. Iteration 01600, Avg-Loss: 7.0054, Accuracy: 0.1425\n",
      "Validation-epoch 3. Iteration 00426, Avg-Loss: 6.3838, Accuracy: 0.2682\n",
      "Train-epoch 4. Iteration 00100, Avg-Loss: 6.0730, Accuracy: 0.1200\n",
      "Train-epoch 4. Iteration 00200, Avg-Loss: 6.8152, Accuracy: 0.1150\n",
      "Train-epoch 4. Iteration 00300, Avg-Loss: 6.6420, Accuracy: 0.1367\n",
      "Train-epoch 4. Iteration 00400, Avg-Loss: 6.9985, Accuracy: 0.1275\n",
      "Train-epoch 4. Iteration 00500, Avg-Loss: 6.8450, Accuracy: 0.1500\n",
      "Train-epoch 4. Iteration 00600, Avg-Loss: 7.0035, Accuracy: 0.1433\n",
      "Train-epoch 4. Iteration 00700, Avg-Loss: 7.0177, Accuracy: 0.1486\n",
      "Train-epoch 4. Iteration 00800, Avg-Loss: 7.1268, Accuracy: 0.1450\n",
      "Train-epoch 4. Iteration 00900, Avg-Loss: 7.1816, Accuracy: 0.1400\n",
      "Train-epoch 4. Iteration 01000, Avg-Loss: 7.1375, Accuracy: 0.1460\n",
      "Train-epoch 4. Iteration 01100, Avg-Loss: 7.3669, Accuracy: 0.1445\n",
      "Train-epoch 4. Iteration 01200, Avg-Loss: 7.3982, Accuracy: 0.1442\n",
      "Train-epoch 4. Iteration 01300, Avg-Loss: 7.2844, Accuracy: 0.1485\n",
      "Train-epoch 4. Iteration 01400, Avg-Loss: 7.2507, Accuracy: 0.1507\n",
      "Train-epoch 4. Iteration 01500, Avg-Loss: 7.1819, Accuracy: 0.1547\n",
      "Train-epoch 4. Iteration 01600, Avg-Loss: 7.2188, Accuracy: 0.1550\n",
      "Validation-epoch 4. Iteration 00426, Avg-Loss: 6.7944, Accuracy: 0.3271\n",
      "Train-epoch 5. Iteration 00100, Avg-Loss: 5.8995, Accuracy: 0.1700\n",
      "Train-epoch 5. Iteration 00200, Avg-Loss: 6.1436, Accuracy: 0.1700\n",
      "Train-epoch 5. Iteration 00300, Avg-Loss: 6.2735, Accuracy: 0.1933\n",
      "Train-epoch 5. Iteration 00400, Avg-Loss: 6.3567, Accuracy: 0.1750\n",
      "Train-epoch 5. Iteration 00500, Avg-Loss: 6.3824, Accuracy: 0.1720\n",
      "Train-epoch 5. Iteration 00600, Avg-Loss: 6.2484, Accuracy: 0.1817\n",
      "Train-epoch 5. Iteration 00700, Avg-Loss: 6.2094, Accuracy: 0.1886\n",
      "Train-epoch 5. Iteration 00800, Avg-Loss: 6.2830, Accuracy: 0.1787\n",
      "Train-epoch 5. Iteration 00900, Avg-Loss: 6.3860, Accuracy: 0.1756\n",
      "Train-epoch 5. Iteration 01000, Avg-Loss: 6.4404, Accuracy: 0.1770\n",
      "Train-epoch 5. Iteration 01100, Avg-Loss: 6.3868, Accuracy: 0.1745\n",
      "Train-epoch 5. Iteration 01200, Avg-Loss: 6.4183, Accuracy: 0.1742\n",
      "Train-epoch 5. Iteration 01300, Avg-Loss: 6.5245, Accuracy: 0.1677\n",
      "Train-epoch 5. Iteration 01400, Avg-Loss: 6.4541, Accuracy: 0.1664\n",
      "Train-epoch 5. Iteration 01500, Avg-Loss: 6.4411, Accuracy: 0.1727\n",
      "Train-epoch 5. Iteration 01600, Avg-Loss: 6.4360, Accuracy: 0.1725\n",
      "Validation-epoch 5. Iteration 00426, Avg-Loss: 5.2399, Accuracy: 0.4282\n",
      "Train-epoch 6. Iteration 00100, Avg-Loss: 7.1364, Accuracy: 0.1600\n",
      "Train-epoch 6. Iteration 00200, Avg-Loss: 6.7297, Accuracy: 0.1800\n",
      "Train-epoch 6. Iteration 00300, Avg-Loss: 6.4549, Accuracy: 0.1733\n",
      "Train-epoch 6. Iteration 00400, Avg-Loss: 6.9226, Accuracy: 0.1700\n",
      "Train-epoch 6. Iteration 00500, Avg-Loss: 6.6362, Accuracy: 0.1820\n",
      "Train-epoch 6. Iteration 00600, Avg-Loss: 6.3821, Accuracy: 0.1883\n",
      "Train-epoch 6. Iteration 00700, Avg-Loss: 6.3790, Accuracy: 0.1900\n",
      "Train-epoch 6. Iteration 00800, Avg-Loss: 6.4416, Accuracy: 0.1925\n",
      "Train-epoch 6. Iteration 00900, Avg-Loss: 6.3705, Accuracy: 0.1933\n",
      "Train-epoch 6. Iteration 01000, Avg-Loss: 6.2881, Accuracy: 0.1980\n",
      "Train-epoch 6. Iteration 01100, Avg-Loss: 6.2879, Accuracy: 0.1982\n",
      "Train-epoch 6. Iteration 01200, Avg-Loss: 6.2235, Accuracy: 0.2017\n",
      "Train-epoch 6. Iteration 01300, Avg-Loss: 6.1696, Accuracy: 0.2015\n",
      "Train-epoch 6. Iteration 01400, Avg-Loss: 6.2302, Accuracy: 0.1950\n",
      "Train-epoch 6. Iteration 01500, Avg-Loss: 6.2044, Accuracy: 0.1967\n",
      "Train-epoch 6. Iteration 01600, Avg-Loss: 6.1944, Accuracy: 0.1988\n",
      "Validation-epoch 6. Iteration 00426, Avg-Loss: 7.2449, Accuracy: 0.3671\n",
      "Train-epoch 7. Iteration 00100, Avg-Loss: 5.3556, Accuracy: 0.2800\n",
      "Train-epoch 7. Iteration 00200, Avg-Loss: 5.4308, Accuracy: 0.2450\n",
      "Train-epoch 7. Iteration 00300, Avg-Loss: 6.1648, Accuracy: 0.2100\n",
      "Train-epoch 7. Iteration 00400, Avg-Loss: 6.3052, Accuracy: 0.2075\n",
      "Train-epoch 7. Iteration 00500, Avg-Loss: 6.5494, Accuracy: 0.1980\n",
      "Train-epoch 7. Iteration 00600, Avg-Loss: 6.5286, Accuracy: 0.1967\n",
      "Train-epoch 7. Iteration 00700, Avg-Loss: 6.5772, Accuracy: 0.2086\n",
      "Train-epoch 7. Iteration 00800, Avg-Loss: 6.6327, Accuracy: 0.2025\n",
      "Train-epoch 7. Iteration 00900, Avg-Loss: 6.7059, Accuracy: 0.2000\n",
      "Train-epoch 7. Iteration 01000, Avg-Loss: 6.6429, Accuracy: 0.2040\n",
      "Train-epoch 7. Iteration 01100, Avg-Loss: 6.5887, Accuracy: 0.2018\n",
      "Train-epoch 7. Iteration 01200, Avg-Loss: 6.5179, Accuracy: 0.2058\n",
      "Train-epoch 7. Iteration 01300, Avg-Loss: 6.5387, Accuracy: 0.2054\n",
      "Train-epoch 7. Iteration 01400, Avg-Loss: 6.5730, Accuracy: 0.2043\n",
      "Train-epoch 7. Iteration 01500, Avg-Loss: 6.5666, Accuracy: 0.2020\n",
      "Train-epoch 7. Iteration 01600, Avg-Loss: 6.6008, Accuracy: 0.2037\n",
      "Validation-epoch 7. Iteration 00426, Avg-Loss: 7.3820, Accuracy: 0.3929\n",
      "Train-epoch 8. Iteration 00100, Avg-Loss: 7.0010, Accuracy: 0.2300\n",
      "Train-epoch 8. Iteration 00200, Avg-Loss: 6.3786, Accuracy: 0.1850\n",
      "Train-epoch 8. Iteration 00300, Avg-Loss: 6.0728, Accuracy: 0.2067\n",
      "Train-epoch 8. Iteration 00400, Avg-Loss: 6.0616, Accuracy: 0.2150\n",
      "Train-epoch 8. Iteration 00500, Avg-Loss: 5.9847, Accuracy: 0.2280\n",
      "Train-epoch 8. Iteration 00600, Avg-Loss: 6.1298, Accuracy: 0.2283\n",
      "Train-epoch 8. Iteration 00700, Avg-Loss: 6.2219, Accuracy: 0.2257\n",
      "Train-epoch 8. Iteration 00800, Avg-Loss: 6.1657, Accuracy: 0.2350\n",
      "Train-epoch 8. Iteration 00900, Avg-Loss: 6.1478, Accuracy: 0.2378\n",
      "Train-epoch 8. Iteration 01000, Avg-Loss: 6.1196, Accuracy: 0.2430\n",
      "Train-epoch 8. Iteration 01100, Avg-Loss: 6.2162, Accuracy: 0.2427\n",
      "Train-epoch 8. Iteration 01200, Avg-Loss: 6.2128, Accuracy: 0.2433\n",
      "Train-epoch 8. Iteration 01300, Avg-Loss: 6.2028, Accuracy: 0.2400\n",
      "Train-epoch 8. Iteration 01400, Avg-Loss: 6.2323, Accuracy: 0.2357\n",
      "Train-epoch 8. Iteration 01500, Avg-Loss: 6.2738, Accuracy: 0.2360\n",
      "Train-epoch 8. Iteration 01600, Avg-Loss: 6.3198, Accuracy: 0.2375\n",
      "Validation-epoch 8. Iteration 00426, Avg-Loss: 7.2606, Accuracy: 0.4071\n",
      "Train-epoch 9. Iteration 00100, Avg-Loss: 5.7803, Accuracy: 0.2900\n",
      "Train-epoch 9. Iteration 00200, Avg-Loss: 5.9869, Accuracy: 0.2650\n",
      "Train-epoch 9. Iteration 00300, Avg-Loss: 5.7887, Accuracy: 0.2400\n",
      "Train-epoch 9. Iteration 00400, Avg-Loss: 5.9960, Accuracy: 0.2450\n",
      "Train-epoch 9. Iteration 00500, Avg-Loss: 5.9520, Accuracy: 0.2420\n",
      "Train-epoch 9. Iteration 00600, Avg-Loss: 5.8550, Accuracy: 0.2367\n",
      "Train-epoch 9. Iteration 00700, Avg-Loss: 5.8947, Accuracy: 0.2357\n",
      "Train-epoch 9. Iteration 00800, Avg-Loss: 5.9224, Accuracy: 0.2412\n",
      "Train-epoch 9. Iteration 00900, Avg-Loss: 5.8817, Accuracy: 0.2456\n",
      "Train-epoch 9. Iteration 01000, Avg-Loss: 5.9467, Accuracy: 0.2440\n",
      "Train-epoch 9. Iteration 01100, Avg-Loss: 5.9801, Accuracy: 0.2464\n",
      "Train-epoch 9. Iteration 01200, Avg-Loss: 5.9988, Accuracy: 0.2433\n",
      "Train-epoch 9. Iteration 01300, Avg-Loss: 6.0798, Accuracy: 0.2400\n",
      "Train-epoch 9. Iteration 01400, Avg-Loss: 6.0498, Accuracy: 0.2414\n",
      "Train-epoch 9. Iteration 01500, Avg-Loss: 6.0081, Accuracy: 0.2467\n",
      "Train-epoch 9. Iteration 01600, Avg-Loss: 5.9650, Accuracy: 0.2475\n",
      "Validation-epoch 9. Iteration 00426, Avg-Loss: 7.3446, Accuracy: 0.3765\n",
      "Train-epoch 10. Iteration 00100, Avg-Loss: 6.1500, Accuracy: 0.2200\n",
      "Train-epoch 10. Iteration 00200, Avg-Loss: 5.8602, Accuracy: 0.2500\n",
      "Train-epoch 10. Iteration 00300, Avg-Loss: 5.9666, Accuracy: 0.2567\n",
      "Train-epoch 10. Iteration 00400, Avg-Loss: 6.0965, Accuracy: 0.2500\n",
      "Train-epoch 10. Iteration 00500, Avg-Loss: 6.0495, Accuracy: 0.2600\n",
      "Train-epoch 10. Iteration 00600, Avg-Loss: 6.0689, Accuracy: 0.2633\n",
      "Train-epoch 10. Iteration 00700, Avg-Loss: 6.0057, Accuracy: 0.2643\n",
      "Train-epoch 10. Iteration 00800, Avg-Loss: 6.0048, Accuracy: 0.2712\n",
      "Train-epoch 10. Iteration 00900, Avg-Loss: 6.0724, Accuracy: 0.2589\n",
      "Train-epoch 10. Iteration 01000, Avg-Loss: 6.0448, Accuracy: 0.2610\n",
      "Train-epoch 10. Iteration 01100, Avg-Loss: 6.0765, Accuracy: 0.2582\n",
      "Train-epoch 10. Iteration 01200, Avg-Loss: 6.0781, Accuracy: 0.2642\n",
      "Train-epoch 10. Iteration 01300, Avg-Loss: 6.1848, Accuracy: 0.2600\n",
      "Train-epoch 10. Iteration 01400, Avg-Loss: 6.1274, Accuracy: 0.2643\n",
      "Train-epoch 10. Iteration 01500, Avg-Loss: 6.1352, Accuracy: 0.2673\n",
      "Train-epoch 10. Iteration 01600, Avg-Loss: 6.1621, Accuracy: 0.2656\n",
      "Validation-epoch 10. Iteration 00426, Avg-Loss: 8.0737, Accuracy: 0.4306\n",
      "Train-epoch 11. Iteration 00100, Avg-Loss: 5.8994, Accuracy: 0.3400\n",
      "Train-epoch 11. Iteration 00200, Avg-Loss: 5.8119, Accuracy: 0.3150\n",
      "Train-epoch 11. Iteration 00300, Avg-Loss: 5.6436, Accuracy: 0.3067\n",
      "Train-epoch 11. Iteration 00400, Avg-Loss: 5.5866, Accuracy: 0.3075\n",
      "Train-epoch 11. Iteration 00500, Avg-Loss: 5.7809, Accuracy: 0.2940\n",
      "Train-epoch 11. Iteration 00600, Avg-Loss: 5.8755, Accuracy: 0.2833\n",
      "Train-epoch 11. Iteration 00700, Avg-Loss: 5.8533, Accuracy: 0.2843\n",
      "Train-epoch 11. Iteration 00800, Avg-Loss: 5.8980, Accuracy: 0.2825\n",
      "Train-epoch 11. Iteration 00900, Avg-Loss: 5.9739, Accuracy: 0.2733\n",
      "Train-epoch 11. Iteration 01000, Avg-Loss: 5.9806, Accuracy: 0.2680\n",
      "Train-epoch 11. Iteration 01100, Avg-Loss: 6.0961, Accuracy: 0.2682\n",
      "Train-epoch 11. Iteration 01200, Avg-Loss: 6.0582, Accuracy: 0.2683\n",
      "Train-epoch 11. Iteration 01300, Avg-Loss: 6.0186, Accuracy: 0.2677\n",
      "Train-epoch 11. Iteration 01400, Avg-Loss: 5.9772, Accuracy: 0.2657\n",
      "Train-epoch 11. Iteration 01500, Avg-Loss: 6.0146, Accuracy: 0.2633\n",
      "Train-epoch 11. Iteration 01600, Avg-Loss: 6.0081, Accuracy: 0.2662\n",
      "Validation-epoch 11. Iteration 00426, Avg-Loss: 5.5471, Accuracy: 0.5412\n",
      "Train-epoch 12. Iteration 00100, Avg-Loss: 7.0047, Accuracy: 0.2500\n",
      "Train-epoch 12. Iteration 00200, Avg-Loss: 7.9722, Accuracy: 0.2050\n",
      "Train-epoch 12. Iteration 00300, Avg-Loss: 7.1076, Accuracy: 0.2433\n",
      "Train-epoch 12. Iteration 00400, Avg-Loss: 6.7052, Accuracy: 0.2675\n",
      "Train-epoch 12. Iteration 00500, Avg-Loss: 6.6245, Accuracy: 0.2700\n",
      "Train-epoch 12. Iteration 00600, Avg-Loss: 6.4595, Accuracy: 0.2667\n",
      "Train-epoch 12. Iteration 00700, Avg-Loss: 6.3380, Accuracy: 0.2686\n",
      "Train-epoch 12. Iteration 00800, Avg-Loss: 6.1796, Accuracy: 0.2800\n",
      "Train-epoch 12. Iteration 00900, Avg-Loss: 6.0495, Accuracy: 0.2800\n",
      "Train-epoch 12. Iteration 01000, Avg-Loss: 6.0406, Accuracy: 0.2810\n",
      "Train-epoch 12. Iteration 01100, Avg-Loss: 5.8798, Accuracy: 0.2882\n",
      "Train-epoch 12. Iteration 01200, Avg-Loss: 5.8392, Accuracy: 0.2908\n",
      "Train-epoch 12. Iteration 01300, Avg-Loss: 5.9639, Accuracy: 0.2846\n",
      "Train-epoch 12. Iteration 01400, Avg-Loss: 5.9585, Accuracy: 0.2814\n",
      "Train-epoch 12. Iteration 01500, Avg-Loss: 6.0064, Accuracy: 0.2800\n",
      "Train-epoch 12. Iteration 01600, Avg-Loss: 5.9421, Accuracy: 0.2787\n",
      "Validation-epoch 12. Iteration 00426, Avg-Loss: 5.7113, Accuracy: 0.4988\n",
      "Train-epoch 13. Iteration 00100, Avg-Loss: 4.8160, Accuracy: 0.3200\n",
      "Train-epoch 13. Iteration 00200, Avg-Loss: 5.4548, Accuracy: 0.3200\n",
      "Train-epoch 13. Iteration 00300, Avg-Loss: 5.6407, Accuracy: 0.2900\n",
      "Train-epoch 13. Iteration 00400, Avg-Loss: 5.8815, Accuracy: 0.2950\n",
      "Train-epoch 13. Iteration 00500, Avg-Loss: 6.0096, Accuracy: 0.3000\n",
      "Train-epoch 13. Iteration 00600, Avg-Loss: 6.0519, Accuracy: 0.2933\n",
      "Train-epoch 13. Iteration 00700, Avg-Loss: 5.8851, Accuracy: 0.3043\n",
      "Train-epoch 13. Iteration 00800, Avg-Loss: 5.9950, Accuracy: 0.2963\n",
      "Train-epoch 13. Iteration 00900, Avg-Loss: 5.8712, Accuracy: 0.2989\n",
      "Train-epoch 13. Iteration 01000, Avg-Loss: 5.7885, Accuracy: 0.2980\n",
      "Train-epoch 13. Iteration 01100, Avg-Loss: 5.8354, Accuracy: 0.2955\n",
      "Train-epoch 13. Iteration 01200, Avg-Loss: 5.8516, Accuracy: 0.2933\n",
      "Train-epoch 13. Iteration 01300, Avg-Loss: 5.9317, Accuracy: 0.2838\n",
      "Train-epoch 13. Iteration 01400, Avg-Loss: 5.8769, Accuracy: 0.2864\n",
      "Train-epoch 13. Iteration 01500, Avg-Loss: 5.7709, Accuracy: 0.2940\n",
      "Train-epoch 13. Iteration 01600, Avg-Loss: 5.7406, Accuracy: 0.2925\n",
      "Validation-epoch 13. Iteration 00426, Avg-Loss: 4.9279, Accuracy: 0.6565\n",
      "Train-epoch 14. Iteration 00100, Avg-Loss: 4.9146, Accuracy: 0.3500\n",
      "Train-epoch 14. Iteration 00200, Avg-Loss: 4.7107, Accuracy: 0.3450\n",
      "Train-epoch 14. Iteration 00300, Avg-Loss: 5.2174, Accuracy: 0.3067\n",
      "Train-epoch 14. Iteration 00400, Avg-Loss: 5.2780, Accuracy: 0.3050\n",
      "Train-epoch 14. Iteration 00500, Avg-Loss: 5.4213, Accuracy: 0.3000\n",
      "Train-epoch 14. Iteration 00600, Avg-Loss: 5.3265, Accuracy: 0.3083\n",
      "Train-epoch 14. Iteration 00700, Avg-Loss: 5.2378, Accuracy: 0.3157\n",
      "Train-epoch 14. Iteration 00800, Avg-Loss: 5.1906, Accuracy: 0.3200\n",
      "Train-epoch 14. Iteration 00900, Avg-Loss: 5.2083, Accuracy: 0.3156\n",
      "Train-epoch 14. Iteration 01000, Avg-Loss: 5.3173, Accuracy: 0.3060\n",
      "Train-epoch 14. Iteration 01100, Avg-Loss: 5.4632, Accuracy: 0.3027\n",
      "Train-epoch 14. Iteration 01200, Avg-Loss: 5.5561, Accuracy: 0.3017\n",
      "Train-epoch 14. Iteration 01300, Avg-Loss: 5.6033, Accuracy: 0.2969\n",
      "Train-epoch 14. Iteration 01400, Avg-Loss: 5.6680, Accuracy: 0.2929\n",
      "Train-epoch 14. Iteration 01500, Avg-Loss: 5.7187, Accuracy: 0.2927\n",
      "Train-epoch 14. Iteration 01600, Avg-Loss: 5.6413, Accuracy: 0.2956\n",
      "Validation-epoch 14. Iteration 00426, Avg-Loss: 5.6292, Accuracy: 0.5271\n",
      "Train-epoch 15. Iteration 00100, Avg-Loss: 4.1825, Accuracy: 0.3900\n",
      "Train-epoch 15. Iteration 00200, Avg-Loss: 4.8956, Accuracy: 0.3150\n",
      "Train-epoch 15. Iteration 00300, Avg-Loss: 5.1275, Accuracy: 0.3233\n",
      "Train-epoch 15. Iteration 00400, Avg-Loss: 5.2748, Accuracy: 0.3175\n",
      "Train-epoch 15. Iteration 00500, Avg-Loss: 5.2681, Accuracy: 0.3120\n",
      "Train-epoch 15. Iteration 00600, Avg-Loss: 5.4208, Accuracy: 0.3067\n",
      "Train-epoch 15. Iteration 00700, Avg-Loss: 5.2128, Accuracy: 0.3243\n",
      "Train-epoch 15. Iteration 00800, Avg-Loss: 5.1748, Accuracy: 0.3312\n",
      "Train-epoch 15. Iteration 00900, Avg-Loss: 5.1478, Accuracy: 0.3300\n",
      "Train-epoch 15. Iteration 01000, Avg-Loss: 5.1400, Accuracy: 0.3300\n",
      "Train-epoch 15. Iteration 01100, Avg-Loss: 5.1596, Accuracy: 0.3264\n",
      "Train-epoch 15. Iteration 01200, Avg-Loss: 5.2381, Accuracy: 0.3200\n",
      "Train-epoch 15. Iteration 01300, Avg-Loss: 5.1951, Accuracy: 0.3200\n",
      "Train-epoch 15. Iteration 01400, Avg-Loss: 5.2142, Accuracy: 0.3200\n",
      "Train-epoch 15. Iteration 01500, Avg-Loss: 5.2571, Accuracy: 0.3220\n",
      "Train-epoch 15. Iteration 01600, Avg-Loss: 5.2504, Accuracy: 0.3250\n",
      "Validation-epoch 15. Iteration 00426, Avg-Loss: 13.3317, Accuracy: 0.3082\n",
      "Train-epoch 16. Iteration 00100, Avg-Loss: 4.1030, Accuracy: 0.3700\n",
      "Train-epoch 16. Iteration 00200, Avg-Loss: 5.3467, Accuracy: 0.3050\n",
      "Train-epoch 16. Iteration 00300, Avg-Loss: 5.4937, Accuracy: 0.3033\n",
      "Train-epoch 16. Iteration 00400, Avg-Loss: 5.5727, Accuracy: 0.2850\n",
      "Train-epoch 16. Iteration 00500, Avg-Loss: 5.3944, Accuracy: 0.2920\n",
      "Train-epoch 16. Iteration 00600, Avg-Loss: 5.1489, Accuracy: 0.3267\n",
      "Train-epoch 16. Iteration 00700, Avg-Loss: 5.3689, Accuracy: 0.3186\n",
      "Train-epoch 16. Iteration 00800, Avg-Loss: 5.3249, Accuracy: 0.3250\n",
      "Train-epoch 16. Iteration 00900, Avg-Loss: 5.2384, Accuracy: 0.3311\n",
      "Train-epoch 16. Iteration 01000, Avg-Loss: 5.3146, Accuracy: 0.3370\n",
      "Train-epoch 16. Iteration 01100, Avg-Loss: 5.3120, Accuracy: 0.3382\n",
      "Train-epoch 16. Iteration 01200, Avg-Loss: 5.2780, Accuracy: 0.3475\n",
      "Train-epoch 16. Iteration 01300, Avg-Loss: 5.2402, Accuracy: 0.3523\n",
      "Train-epoch 16. Iteration 01400, Avg-Loss: 5.3880, Accuracy: 0.3464\n",
      "Train-epoch 16. Iteration 01500, Avg-Loss: 5.4729, Accuracy: 0.3393\n",
      "Train-epoch 16. Iteration 01600, Avg-Loss: 5.4119, Accuracy: 0.3381\n",
      "Validation-epoch 16. Iteration 00426, Avg-Loss: 4.8008, Accuracy: 0.5929\n",
      "Train-epoch 17. Iteration 00100, Avg-Loss: 3.9828, Accuracy: 0.3900\n",
      "Train-epoch 17. Iteration 00200, Avg-Loss: 3.9294, Accuracy: 0.3700\n",
      "Train-epoch 17. Iteration 00300, Avg-Loss: 4.4038, Accuracy: 0.3733\n",
      "Train-epoch 17. Iteration 00400, Avg-Loss: 4.5636, Accuracy: 0.3775\n",
      "Train-epoch 17. Iteration 00500, Avg-Loss: 4.6806, Accuracy: 0.3620\n",
      "Train-epoch 17. Iteration 00600, Avg-Loss: 4.8345, Accuracy: 0.3533\n",
      "Train-epoch 17. Iteration 00700, Avg-Loss: 4.9510, Accuracy: 0.3429\n",
      "Train-epoch 17. Iteration 00800, Avg-Loss: 4.9761, Accuracy: 0.3375\n",
      "Train-epoch 17. Iteration 00900, Avg-Loss: 4.9051, Accuracy: 0.3411\n",
      "Train-epoch 17. Iteration 01000, Avg-Loss: 4.9693, Accuracy: 0.3430\n",
      "Train-epoch 17. Iteration 01100, Avg-Loss: 5.0411, Accuracy: 0.3382\n",
      "Train-epoch 17. Iteration 01200, Avg-Loss: 5.0522, Accuracy: 0.3408\n",
      "Train-epoch 17. Iteration 01300, Avg-Loss: 5.0489, Accuracy: 0.3415\n",
      "Train-epoch 17. Iteration 01400, Avg-Loss: 5.0206, Accuracy: 0.3407\n",
      "Train-epoch 17. Iteration 01500, Avg-Loss: 5.0285, Accuracy: 0.3400\n",
      "Train-epoch 17. Iteration 01600, Avg-Loss: 5.0480, Accuracy: 0.3406\n",
      "Validation-epoch 17. Iteration 00426, Avg-Loss: 10.8323, Accuracy: 0.4376\n",
      "Train-epoch 18. Iteration 00100, Avg-Loss: 5.0616, Accuracy: 0.2900\n",
      "Train-epoch 18. Iteration 00200, Avg-Loss: 4.8869, Accuracy: 0.3050\n",
      "Train-epoch 18. Iteration 00300, Avg-Loss: 4.3968, Accuracy: 0.3400\n",
      "Train-epoch 18. Iteration 00400, Avg-Loss: 4.5394, Accuracy: 0.3400\n",
      "Train-epoch 18. Iteration 00500, Avg-Loss: 4.4632, Accuracy: 0.3600\n",
      "Train-epoch 18. Iteration 00600, Avg-Loss: 4.7119, Accuracy: 0.3550\n",
      "Train-epoch 18. Iteration 00700, Avg-Loss: 4.7478, Accuracy: 0.3514\n",
      "Train-epoch 18. Iteration 00800, Avg-Loss: 4.9836, Accuracy: 0.3450\n",
      "Train-epoch 18. Iteration 00900, Avg-Loss: 5.1848, Accuracy: 0.3356\n",
      "Train-epoch 18. Iteration 01000, Avg-Loss: 5.2360, Accuracy: 0.3330\n",
      "Train-epoch 18. Iteration 01100, Avg-Loss: 5.2852, Accuracy: 0.3355\n",
      "Train-epoch 18. Iteration 01200, Avg-Loss: 5.2753, Accuracy: 0.3342\n",
      "Train-epoch 18. Iteration 01300, Avg-Loss: 5.2754, Accuracy: 0.3362\n",
      "Train-epoch 18. Iteration 01400, Avg-Loss: 5.2658, Accuracy: 0.3321\n",
      "Train-epoch 18. Iteration 01500, Avg-Loss: 5.3316, Accuracy: 0.3347\n",
      "Train-epoch 18. Iteration 01600, Avg-Loss: 5.3028, Accuracy: 0.3356\n",
      "Validation-epoch 18. Iteration 00426, Avg-Loss: 4.8941, Accuracy: 0.5953\n",
      "Train-epoch 19. Iteration 00100, Avg-Loss: 3.7430, Accuracy: 0.4400\n",
      "Train-epoch 19. Iteration 00200, Avg-Loss: 4.0432, Accuracy: 0.4150\n",
      "Train-epoch 19. Iteration 00300, Avg-Loss: 4.6295, Accuracy: 0.3867\n",
      "Train-epoch 19. Iteration 00400, Avg-Loss: 4.7567, Accuracy: 0.3975\n",
      "Train-epoch 19. Iteration 00500, Avg-Loss: 4.8510, Accuracy: 0.3800\n",
      "Train-epoch 19. Iteration 00600, Avg-Loss: 4.9964, Accuracy: 0.3650\n",
      "Train-epoch 19. Iteration 00700, Avg-Loss: 4.9751, Accuracy: 0.3671\n",
      "Train-epoch 19. Iteration 00800, Avg-Loss: 5.0969, Accuracy: 0.3638\n",
      "Train-epoch 19. Iteration 00900, Avg-Loss: 5.1482, Accuracy: 0.3644\n",
      "Train-epoch 19. Iteration 01000, Avg-Loss: 5.1796, Accuracy: 0.3650\n",
      "Train-epoch 19. Iteration 01100, Avg-Loss: 5.2497, Accuracy: 0.3727\n",
      "Train-epoch 19. Iteration 01200, Avg-Loss: 5.2716, Accuracy: 0.3775\n",
      "Train-epoch 19. Iteration 01300, Avg-Loss: 5.2233, Accuracy: 0.3746\n",
      "Train-epoch 19. Iteration 01400, Avg-Loss: 5.1967, Accuracy: 0.3743\n",
      "Train-epoch 19. Iteration 01500, Avg-Loss: 5.2722, Accuracy: 0.3680\n",
      "Train-epoch 19. Iteration 01600, Avg-Loss: 5.3967, Accuracy: 0.3613\n",
      "Validation-epoch 19. Iteration 00426, Avg-Loss: 14.3623, Accuracy: 0.3647\n",
      "Train-epoch 20. Iteration 00100, Avg-Loss: 6.3835, Accuracy: 0.2900\n",
      "Train-epoch 20. Iteration 00200, Avg-Loss: 5.9604, Accuracy: 0.3400\n",
      "Train-epoch 20. Iteration 00300, Avg-Loss: 5.8177, Accuracy: 0.3433\n",
      "Train-epoch 20. Iteration 00400, Avg-Loss: 5.4075, Accuracy: 0.3575\n",
      "Train-epoch 20. Iteration 00500, Avg-Loss: 5.2221, Accuracy: 0.3620\n",
      "Train-epoch 20. Iteration 00600, Avg-Loss: 5.3908, Accuracy: 0.3383\n",
      "Train-epoch 20. Iteration 00700, Avg-Loss: 5.5498, Accuracy: 0.3471\n",
      "Train-epoch 20. Iteration 00800, Avg-Loss: 5.3975, Accuracy: 0.3513\n",
      "Train-epoch 20. Iteration 00900, Avg-Loss: 5.3384, Accuracy: 0.3522\n",
      "Train-epoch 20. Iteration 01000, Avg-Loss: 5.3051, Accuracy: 0.3470\n",
      "Train-epoch 20. Iteration 01100, Avg-Loss: 5.2241, Accuracy: 0.3527\n",
      "Train-epoch 20. Iteration 01200, Avg-Loss: 5.2206, Accuracy: 0.3567\n",
      "Train-epoch 20. Iteration 01300, Avg-Loss: 5.4761, Accuracy: 0.3485\n",
      "Train-epoch 20. Iteration 01400, Avg-Loss: 5.4491, Accuracy: 0.3486\n",
      "Train-epoch 20. Iteration 01500, Avg-Loss: 5.4231, Accuracy: 0.3493\n",
      "Train-epoch 20. Iteration 01600, Avg-Loss: 5.3359, Accuracy: 0.3569\n",
      "Validation-epoch 20. Iteration 00426, Avg-Loss: 8.8699, Accuracy: 0.5718\n",
      "Train-epoch 21. Iteration 00100, Avg-Loss: 4.7845, Accuracy: 0.4100\n",
      "Train-epoch 21. Iteration 00200, Avg-Loss: 5.5532, Accuracy: 0.3550\n",
      "Train-epoch 21. Iteration 00300, Avg-Loss: 5.0932, Accuracy: 0.3600\n",
      "Train-epoch 21. Iteration 00400, Avg-Loss: 5.3751, Accuracy: 0.3575\n",
      "Train-epoch 21. Iteration 00500, Avg-Loss: 5.5094, Accuracy: 0.3520\n",
      "Train-epoch 21. Iteration 00600, Avg-Loss: 5.4274, Accuracy: 0.3667\n",
      "Train-epoch 21. Iteration 00700, Avg-Loss: 5.2790, Accuracy: 0.3786\n",
      "Train-epoch 21. Iteration 00800, Avg-Loss: 5.4826, Accuracy: 0.3650\n",
      "Train-epoch 21. Iteration 00900, Avg-Loss: 5.5542, Accuracy: 0.3644\n",
      "Train-epoch 21. Iteration 01000, Avg-Loss: 5.4342, Accuracy: 0.3660\n",
      "Train-epoch 21. Iteration 01100, Avg-Loss: 5.2703, Accuracy: 0.3745\n",
      "Train-epoch 21. Iteration 01200, Avg-Loss: 5.2667, Accuracy: 0.3750\n",
      "Train-epoch 21. Iteration 01300, Avg-Loss: 5.2425, Accuracy: 0.3754\n",
      "Train-epoch 21. Iteration 01400, Avg-Loss: 5.3261, Accuracy: 0.3686\n",
      "Train-epoch 21. Iteration 01500, Avg-Loss: 5.2520, Accuracy: 0.3720\n",
      "Train-epoch 21. Iteration 01600, Avg-Loss: 5.2404, Accuracy: 0.3725\n",
      "Validation-epoch 21. Iteration 00426, Avg-Loss: 5.4109, Accuracy: 0.6518\n",
      "Train-epoch 22. Iteration 00100, Avg-Loss: 6.1306, Accuracy: 0.3900\n",
      "Train-epoch 22. Iteration 00200, Avg-Loss: 5.4367, Accuracy: 0.3900\n",
      "Train-epoch 22. Iteration 00300, Avg-Loss: 5.9725, Accuracy: 0.3767\n",
      "Train-epoch 22. Iteration 00400, Avg-Loss: 5.4096, Accuracy: 0.3925\n",
      "Train-epoch 22. Iteration 00500, Avg-Loss: 5.4458, Accuracy: 0.3940\n",
      "Train-epoch 22. Iteration 00600, Avg-Loss: 5.2969, Accuracy: 0.3983\n",
      "Train-epoch 22. Iteration 00700, Avg-Loss: 5.5473, Accuracy: 0.3871\n",
      "Train-epoch 22. Iteration 00800, Avg-Loss: 5.4387, Accuracy: 0.3850\n",
      "Train-epoch 22. Iteration 00900, Avg-Loss: 5.5449, Accuracy: 0.3789\n",
      "Train-epoch 22. Iteration 01000, Avg-Loss: 5.4041, Accuracy: 0.3870\n",
      "Train-epoch 22. Iteration 01100, Avg-Loss: 5.2806, Accuracy: 0.3827\n",
      "Train-epoch 22. Iteration 01200, Avg-Loss: 5.2437, Accuracy: 0.3800\n",
      "Train-epoch 22. Iteration 01300, Avg-Loss: 5.2332, Accuracy: 0.3800\n",
      "Train-epoch 22. Iteration 01400, Avg-Loss: 5.2809, Accuracy: 0.3736\n",
      "Train-epoch 22. Iteration 01500, Avg-Loss: 5.1830, Accuracy: 0.3787\n",
      "Train-epoch 22. Iteration 01600, Avg-Loss: 5.2456, Accuracy: 0.3775\n",
      "Validation-epoch 22. Iteration 00426, Avg-Loss: 10.3497, Accuracy: 0.5129\n",
      "Train-epoch 23. Iteration 00100, Avg-Loss: 6.4884, Accuracy: 0.3000\n",
      "Train-epoch 23. Iteration 00200, Avg-Loss: 5.2891, Accuracy: 0.3500\n",
      "Train-epoch 23. Iteration 00300, Avg-Loss: 4.8242, Accuracy: 0.3500\n",
      "Train-epoch 23. Iteration 00400, Avg-Loss: 4.9403, Accuracy: 0.3550\n",
      "Train-epoch 23. Iteration 00500, Avg-Loss: 5.2226, Accuracy: 0.3460\n",
      "Train-epoch 23. Iteration 00600, Avg-Loss: 5.3293, Accuracy: 0.3517\n",
      "Train-epoch 23. Iteration 00700, Avg-Loss: 5.4349, Accuracy: 0.3514\n",
      "Train-epoch 23. Iteration 00800, Avg-Loss: 5.5039, Accuracy: 0.3500\n",
      "Train-epoch 23. Iteration 00900, Avg-Loss: 5.3387, Accuracy: 0.3533\n",
      "Train-epoch 23. Iteration 01000, Avg-Loss: 5.3028, Accuracy: 0.3640\n",
      "Train-epoch 23. Iteration 01100, Avg-Loss: 5.2769, Accuracy: 0.3673\n",
      "Train-epoch 23. Iteration 01200, Avg-Loss: 5.3182, Accuracy: 0.3658\n",
      "Train-epoch 23. Iteration 01300, Avg-Loss: 5.2714, Accuracy: 0.3654\n",
      "Train-epoch 23. Iteration 01400, Avg-Loss: 5.1765, Accuracy: 0.3707\n",
      "Train-epoch 23. Iteration 01500, Avg-Loss: 5.1494, Accuracy: 0.3680\n",
      "Train-epoch 23. Iteration 01600, Avg-Loss: 5.1052, Accuracy: 0.3694\n",
      "Validation-epoch 23. Iteration 00426, Avg-Loss: 7.4658, Accuracy: 0.5741\n",
      "Train-epoch 24. Iteration 00100, Avg-Loss: 5.9189, Accuracy: 0.3500\n",
      "Train-epoch 24. Iteration 00200, Avg-Loss: 5.6856, Accuracy: 0.3850\n",
      "Train-epoch 24. Iteration 00300, Avg-Loss: 5.3557, Accuracy: 0.3867\n",
      "Train-epoch 24. Iteration 00400, Avg-Loss: 5.2403, Accuracy: 0.3900\n",
      "Train-epoch 24. Iteration 00500, Avg-Loss: 5.1873, Accuracy: 0.3880\n",
      "Train-epoch 24. Iteration 00600, Avg-Loss: 4.9499, Accuracy: 0.4000\n",
      "Train-epoch 24. Iteration 00700, Avg-Loss: 4.8641, Accuracy: 0.4029\n",
      "Train-epoch 24. Iteration 00800, Avg-Loss: 4.7494, Accuracy: 0.4050\n",
      "Train-epoch 24. Iteration 00900, Avg-Loss: 4.7388, Accuracy: 0.3978\n",
      "Train-epoch 24. Iteration 01000, Avg-Loss: 4.8035, Accuracy: 0.3990\n",
      "Train-epoch 24. Iteration 01100, Avg-Loss: 4.7314, Accuracy: 0.4018\n",
      "Train-epoch 24. Iteration 01200, Avg-Loss: 4.7450, Accuracy: 0.4008\n",
      "Train-epoch 24. Iteration 01300, Avg-Loss: 4.7246, Accuracy: 0.4046\n",
      "Train-epoch 24. Iteration 01400, Avg-Loss: 4.6826, Accuracy: 0.4029\n",
      "Train-epoch 24. Iteration 01500, Avg-Loss: 4.8048, Accuracy: 0.3980\n",
      "Train-epoch 24. Iteration 01600, Avg-Loss: 4.9093, Accuracy: 0.3962\n",
      "Validation-epoch 24. Iteration 00426, Avg-Loss: 7.5939, Accuracy: 0.5365\n",
      "Train-epoch 25. Iteration 00100, Avg-Loss: 4.4875, Accuracy: 0.4800\n",
      "Train-epoch 25. Iteration 00200, Avg-Loss: 3.9300, Accuracy: 0.4900\n",
      "Train-epoch 25. Iteration 00300, Avg-Loss: 4.3436, Accuracy: 0.4567\n",
      "Train-epoch 25. Iteration 00400, Avg-Loss: 4.6031, Accuracy: 0.4450\n",
      "Train-epoch 25. Iteration 00500, Avg-Loss: 4.8244, Accuracy: 0.4340\n",
      "Train-epoch 25. Iteration 00600, Avg-Loss: 4.6437, Accuracy: 0.4383\n",
      "Train-epoch 25. Iteration 00700, Avg-Loss: 4.6583, Accuracy: 0.4357\n",
      "Train-epoch 25. Iteration 00800, Avg-Loss: 4.6479, Accuracy: 0.4275\n",
      "Train-epoch 25. Iteration 00900, Avg-Loss: 4.6932, Accuracy: 0.4200\n",
      "Train-epoch 25. Iteration 01000, Avg-Loss: 4.7893, Accuracy: 0.4140\n",
      "Train-epoch 25. Iteration 01100, Avg-Loss: 4.7472, Accuracy: 0.4100\n",
      "Train-epoch 25. Iteration 01200, Avg-Loss: 4.6660, Accuracy: 0.4133\n",
      "Train-epoch 25. Iteration 01300, Avg-Loss: 4.6328, Accuracy: 0.4200\n",
      "Train-epoch 25. Iteration 01400, Avg-Loss: 4.5772, Accuracy: 0.4200\n",
      "Train-epoch 25. Iteration 01500, Avg-Loss: 4.5806, Accuracy: 0.4180\n",
      "Train-epoch 25. Iteration 01600, Avg-Loss: 4.5200, Accuracy: 0.4206\n",
      "Validation-epoch 25. Iteration 00426, Avg-Loss: 9.1550, Accuracy: 0.5271\n",
      "Train-epoch 26. Iteration 00100, Avg-Loss: 7.0992, Accuracy: 0.3400\n",
      "Train-epoch 26. Iteration 00200, Avg-Loss: 6.0173, Accuracy: 0.3900\n",
      "Train-epoch 26. Iteration 00300, Avg-Loss: 6.3580, Accuracy: 0.3767\n",
      "Train-epoch 26. Iteration 00400, Avg-Loss: 6.1295, Accuracy: 0.3800\n",
      "Train-epoch 26. Iteration 00500, Avg-Loss: 5.8749, Accuracy: 0.3860\n",
      "Train-epoch 26. Iteration 00600, Avg-Loss: 5.5408, Accuracy: 0.3967\n",
      "Train-epoch 26. Iteration 00700, Avg-Loss: 5.3198, Accuracy: 0.4086\n",
      "Train-epoch 26. Iteration 00800, Avg-Loss: 5.1069, Accuracy: 0.4238\n",
      "Train-epoch 26. Iteration 00900, Avg-Loss: 5.0591, Accuracy: 0.4211\n",
      "Train-epoch 26. Iteration 01000, Avg-Loss: 5.0670, Accuracy: 0.4200\n",
      "Train-epoch 26. Iteration 01100, Avg-Loss: 5.1702, Accuracy: 0.4073\n",
      "Train-epoch 26. Iteration 01200, Avg-Loss: 5.0561, Accuracy: 0.4108\n",
      "Train-epoch 26. Iteration 01300, Avg-Loss: 5.0552, Accuracy: 0.4100\n",
      "Train-epoch 26. Iteration 01400, Avg-Loss: 5.0764, Accuracy: 0.4100\n",
      "Train-epoch 26. Iteration 01500, Avg-Loss: 5.0086, Accuracy: 0.4100\n",
      "Train-epoch 26. Iteration 01600, Avg-Loss: 5.0407, Accuracy: 0.4050\n",
      "Validation-epoch 26. Iteration 00426, Avg-Loss: 6.7864, Accuracy: 0.5906\n",
      "Train-epoch 27. Iteration 00100, Avg-Loss: 3.7345, Accuracy: 0.5100\n",
      "Train-epoch 27. Iteration 00200, Avg-Loss: 4.6822, Accuracy: 0.4250\n",
      "Train-epoch 27. Iteration 00300, Avg-Loss: 4.5647, Accuracy: 0.4133\n",
      "Train-epoch 27. Iteration 00400, Avg-Loss: 4.9360, Accuracy: 0.3775\n",
      "Train-epoch 27. Iteration 00500, Avg-Loss: 4.9071, Accuracy: 0.3780\n",
      "Train-epoch 27. Iteration 00600, Avg-Loss: 4.9898, Accuracy: 0.3800\n",
      "Train-epoch 27. Iteration 00700, Avg-Loss: 4.9760, Accuracy: 0.3857\n",
      "Train-epoch 27. Iteration 00800, Avg-Loss: 4.9062, Accuracy: 0.3987\n",
      "Train-epoch 27. Iteration 00900, Avg-Loss: 4.9927, Accuracy: 0.3944\n",
      "Train-epoch 27. Iteration 01000, Avg-Loss: 5.0188, Accuracy: 0.3990\n",
      "Train-epoch 27. Iteration 01100, Avg-Loss: 4.9840, Accuracy: 0.4009\n",
      "Train-epoch 27. Iteration 01200, Avg-Loss: 4.9074, Accuracy: 0.4075\n",
      "Train-epoch 27. Iteration 01300, Avg-Loss: 4.8089, Accuracy: 0.4108\n",
      "Train-epoch 27. Iteration 01400, Avg-Loss: 4.9035, Accuracy: 0.4100\n",
      "Train-epoch 27. Iteration 01500, Avg-Loss: 4.8468, Accuracy: 0.4140\n",
      "Train-epoch 27. Iteration 01600, Avg-Loss: 4.8011, Accuracy: 0.4163\n",
      "Validation-epoch 27. Iteration 00426, Avg-Loss: 6.8293, Accuracy: 0.6659\n",
      "Train-epoch 28. Iteration 00100, Avg-Loss: 5.8999, Accuracy: 0.3500\n",
      "Train-epoch 28. Iteration 00200, Avg-Loss: 4.9604, Accuracy: 0.3800\n",
      "Train-epoch 28. Iteration 00300, Avg-Loss: 4.8822, Accuracy: 0.4033\n",
      "Train-epoch 28. Iteration 00400, Avg-Loss: 4.8331, Accuracy: 0.4075\n",
      "Train-epoch 28. Iteration 00500, Avg-Loss: 4.8637, Accuracy: 0.4040\n",
      "Train-epoch 28. Iteration 00600, Avg-Loss: 4.6924, Accuracy: 0.4050\n",
      "Train-epoch 28. Iteration 00700, Avg-Loss: 4.5501, Accuracy: 0.4171\n",
      "Train-epoch 28. Iteration 00800, Avg-Loss: 4.5250, Accuracy: 0.4113\n",
      "Train-epoch 28. Iteration 00900, Avg-Loss: 4.4874, Accuracy: 0.4167\n",
      "Train-epoch 28. Iteration 01000, Avg-Loss: 4.5121, Accuracy: 0.4140\n",
      "Train-epoch 28. Iteration 01100, Avg-Loss: 4.5483, Accuracy: 0.4109\n",
      "Train-epoch 28. Iteration 01200, Avg-Loss: 4.6100, Accuracy: 0.4075\n",
      "Train-epoch 28. Iteration 01300, Avg-Loss: 4.5497, Accuracy: 0.4146\n",
      "Train-epoch 28. Iteration 01400, Avg-Loss: 4.5675, Accuracy: 0.4143\n",
      "Train-epoch 28. Iteration 01500, Avg-Loss: 4.5586, Accuracy: 0.4133\n",
      "Train-epoch 28. Iteration 01600, Avg-Loss: 4.5930, Accuracy: 0.4138\n",
      "Validation-epoch 28. Iteration 00426, Avg-Loss: 14.7133, Accuracy: 0.4071\n",
      "Train-epoch 29. Iteration 00100, Avg-Loss: 5.9522, Accuracy: 0.4200\n",
      "Train-epoch 29. Iteration 00200, Avg-Loss: 5.3344, Accuracy: 0.4400\n",
      "Train-epoch 29. Iteration 00300, Avg-Loss: 4.8825, Accuracy: 0.4467\n",
      "Train-epoch 29. Iteration 00400, Avg-Loss: 5.0262, Accuracy: 0.4500\n",
      "Train-epoch 29. Iteration 00500, Avg-Loss: 4.9466, Accuracy: 0.4480\n",
      "Train-epoch 29. Iteration 00600, Avg-Loss: 4.9411, Accuracy: 0.4350\n",
      "Train-epoch 29. Iteration 00700, Avg-Loss: 4.6075, Accuracy: 0.4486\n",
      "Train-epoch 29. Iteration 00800, Avg-Loss: 4.6788, Accuracy: 0.4475\n",
      "Train-epoch 29. Iteration 00900, Avg-Loss: 4.6789, Accuracy: 0.4467\n",
      "Train-epoch 29. Iteration 01000, Avg-Loss: 4.5474, Accuracy: 0.4540\n",
      "Train-epoch 29. Iteration 01100, Avg-Loss: 4.7866, Accuracy: 0.4445\n",
      "Train-epoch 29. Iteration 01200, Avg-Loss: 4.7364, Accuracy: 0.4425\n",
      "Train-epoch 29. Iteration 01300, Avg-Loss: 4.6905, Accuracy: 0.4462\n",
      "Train-epoch 29. Iteration 01400, Avg-Loss: 4.6429, Accuracy: 0.4457\n",
      "Train-epoch 29. Iteration 01500, Avg-Loss: 4.6444, Accuracy: 0.4413\n",
      "Train-epoch 29. Iteration 01600, Avg-Loss: 4.5703, Accuracy: 0.4444\n",
      "Validation-epoch 29. Iteration 00426, Avg-Loss: 14.8553, Accuracy: 0.4588\n",
      "Train-epoch 30. Iteration 00100, Avg-Loss: 5.6884, Accuracy: 0.4100\n",
      "Train-epoch 30. Iteration 00200, Avg-Loss: 5.3839, Accuracy: 0.3750\n",
      "Train-epoch 30. Iteration 00300, Avg-Loss: 4.7911, Accuracy: 0.4000\n",
      "Train-epoch 30. Iteration 00400, Avg-Loss: 4.4004, Accuracy: 0.4425\n",
      "Train-epoch 30. Iteration 00500, Avg-Loss: 4.1628, Accuracy: 0.4500\n",
      "Train-epoch 30. Iteration 00600, Avg-Loss: 4.2006, Accuracy: 0.4517\n",
      "Train-epoch 30. Iteration 00700, Avg-Loss: 4.3610, Accuracy: 0.4443\n",
      "Train-epoch 30. Iteration 00800, Avg-Loss: 4.4546, Accuracy: 0.4375\n",
      "Train-epoch 30. Iteration 00900, Avg-Loss: 4.4031, Accuracy: 0.4433\n",
      "Train-epoch 30. Iteration 01000, Avg-Loss: 4.3826, Accuracy: 0.4430\n",
      "Train-epoch 30. Iteration 01100, Avg-Loss: 4.4789, Accuracy: 0.4391\n",
      "Train-epoch 30. Iteration 01200, Avg-Loss: 4.5191, Accuracy: 0.4392\n",
      "Train-epoch 30. Iteration 01300, Avg-Loss: 4.4356, Accuracy: 0.4392\n",
      "Train-epoch 30. Iteration 01400, Avg-Loss: 4.4552, Accuracy: 0.4393\n",
      "Train-epoch 30. Iteration 01500, Avg-Loss: 4.4738, Accuracy: 0.4373\n",
      "Train-epoch 30. Iteration 01600, Avg-Loss: 4.4554, Accuracy: 0.4363\n",
      "Validation-epoch 30. Iteration 00426, Avg-Loss: 15.5842, Accuracy: 0.4329\n",
      "Train-epoch 31. Iteration 00100, Avg-Loss: 4.9844, Accuracy: 0.5100\n",
      "Train-epoch 31. Iteration 00200, Avg-Loss: 5.0322, Accuracy: 0.4600\n",
      "Train-epoch 31. Iteration 00300, Avg-Loss: 4.7537, Accuracy: 0.4933\n",
      "Train-epoch 31. Iteration 00400, Avg-Loss: 4.6158, Accuracy: 0.4775\n",
      "Train-epoch 31. Iteration 00500, Avg-Loss: 4.4725, Accuracy: 0.4760\n",
      "Train-epoch 31. Iteration 00600, Avg-Loss: 4.6192, Accuracy: 0.4667\n",
      "Train-epoch 31. Iteration 00700, Avg-Loss: 4.6007, Accuracy: 0.4571\n",
      "Train-epoch 31. Iteration 00800, Avg-Loss: 4.4930, Accuracy: 0.4537\n",
      "Train-epoch 31. Iteration 00900, Avg-Loss: 4.6098, Accuracy: 0.4422\n",
      "Train-epoch 31. Iteration 01000, Avg-Loss: 4.4366, Accuracy: 0.4530\n",
      "Train-epoch 31. Iteration 01100, Avg-Loss: 4.5282, Accuracy: 0.4509\n",
      "Train-epoch 31. Iteration 01200, Avg-Loss: 4.5451, Accuracy: 0.4492\n",
      "Train-epoch 31. Iteration 01300, Avg-Loss: 4.5947, Accuracy: 0.4400\n",
      "Train-epoch 31. Iteration 01400, Avg-Loss: 4.5683, Accuracy: 0.4357\n",
      "Train-epoch 31. Iteration 01500, Avg-Loss: 4.5556, Accuracy: 0.4373\n",
      "Train-epoch 31. Iteration 01600, Avg-Loss: 4.4820, Accuracy: 0.4450\n",
      "Validation-epoch 31. Iteration 00426, Avg-Loss: 10.1436, Accuracy: 0.5365\n",
      "Train-epoch 32. Iteration 00100, Avg-Loss: 2.7604, Accuracy: 0.4800\n",
      "Train-epoch 32. Iteration 00200, Avg-Loss: 3.7264, Accuracy: 0.4600\n",
      "Train-epoch 32. Iteration 00300, Avg-Loss: 3.6859, Accuracy: 0.4867\n",
      "Train-epoch 32. Iteration 00400, Avg-Loss: 3.8502, Accuracy: 0.4900\n",
      "Train-epoch 32. Iteration 00500, Avg-Loss: 4.0066, Accuracy: 0.4760\n",
      "Train-epoch 32. Iteration 00600, Avg-Loss: 4.1977, Accuracy: 0.4550\n",
      "Train-epoch 32. Iteration 00700, Avg-Loss: 4.0760, Accuracy: 0.4629\n",
      "Train-epoch 32. Iteration 00800, Avg-Loss: 4.0896, Accuracy: 0.4612\n",
      "Train-epoch 32. Iteration 00900, Avg-Loss: 4.1180, Accuracy: 0.4622\n",
      "Train-epoch 32. Iteration 01000, Avg-Loss: 4.1406, Accuracy: 0.4550\n",
      "Train-epoch 32. Iteration 01100, Avg-Loss: 4.1742, Accuracy: 0.4491\n",
      "Train-epoch 32. Iteration 01200, Avg-Loss: 4.2290, Accuracy: 0.4475\n",
      "Train-epoch 32. Iteration 01300, Avg-Loss: 4.2271, Accuracy: 0.4477\n",
      "Train-epoch 32. Iteration 01400, Avg-Loss: 4.1522, Accuracy: 0.4514\n",
      "Train-epoch 32. Iteration 01500, Avg-Loss: 4.1100, Accuracy: 0.4520\n",
      "Train-epoch 32. Iteration 01600, Avg-Loss: 4.1478, Accuracy: 0.4494\n",
      "Validation-epoch 32. Iteration 00426, Avg-Loss: 14.7345, Accuracy: 0.4824\n",
      "Train-epoch 33. Iteration 00100, Avg-Loss: 3.7434, Accuracy: 0.5600\n",
      "Train-epoch 33. Iteration 00200, Avg-Loss: 4.1094, Accuracy: 0.5250\n",
      "Train-epoch 33. Iteration 00300, Avg-Loss: 4.6345, Accuracy: 0.4767\n",
      "Train-epoch 33. Iteration 00400, Avg-Loss: 4.3336, Accuracy: 0.4800\n",
      "Train-epoch 33. Iteration 00500, Avg-Loss: 4.4422, Accuracy: 0.4720\n",
      "Train-epoch 33. Iteration 00600, Avg-Loss: 4.5639, Accuracy: 0.4683\n",
      "Train-epoch 33. Iteration 00700, Avg-Loss: 4.6395, Accuracy: 0.4586\n",
      "Train-epoch 33. Iteration 00800, Avg-Loss: 4.4421, Accuracy: 0.4575\n",
      "Train-epoch 33. Iteration 00900, Avg-Loss: 4.5982, Accuracy: 0.4611\n",
      "Train-epoch 33. Iteration 01000, Avg-Loss: 4.5738, Accuracy: 0.4660\n",
      "Train-epoch 33. Iteration 01100, Avg-Loss: 4.6450, Accuracy: 0.4564\n",
      "Train-epoch 33. Iteration 01200, Avg-Loss: 4.5578, Accuracy: 0.4608\n",
      "Train-epoch 33. Iteration 01300, Avg-Loss: 4.5145, Accuracy: 0.4646\n",
      "Train-epoch 33. Iteration 01400, Avg-Loss: 4.5828, Accuracy: 0.4593\n",
      "Train-epoch 33. Iteration 01500, Avg-Loss: 4.6164, Accuracy: 0.4600\n",
      "Train-epoch 33. Iteration 01600, Avg-Loss: 4.6182, Accuracy: 0.4600\n",
      "Validation-epoch 33. Iteration 00426, Avg-Loss: 10.1144, Accuracy: 0.5859\n",
      "Train-epoch 34. Iteration 00100, Avg-Loss: 6.7606, Accuracy: 0.2800\n",
      "Train-epoch 34. Iteration 00200, Avg-Loss: 5.3970, Accuracy: 0.3400\n",
      "Train-epoch 34. Iteration 00300, Avg-Loss: 5.2516, Accuracy: 0.3800\n",
      "Train-epoch 34. Iteration 00400, Avg-Loss: 4.7425, Accuracy: 0.4175\n",
      "Train-epoch 34. Iteration 00500, Avg-Loss: 4.6918, Accuracy: 0.4220\n",
      "Train-epoch 34. Iteration 00600, Avg-Loss: 4.7825, Accuracy: 0.4167\n",
      "Train-epoch 34. Iteration 00700, Avg-Loss: 4.8180, Accuracy: 0.4114\n",
      "Train-epoch 34. Iteration 00800, Avg-Loss: 4.6884, Accuracy: 0.4313\n",
      "Train-epoch 34. Iteration 00900, Avg-Loss: 4.6976, Accuracy: 0.4278\n",
      "Train-epoch 34. Iteration 01000, Avg-Loss: 4.6032, Accuracy: 0.4330\n",
      "Train-epoch 34. Iteration 01100, Avg-Loss: 4.5149, Accuracy: 0.4400\n",
      "Train-epoch 34. Iteration 01200, Avg-Loss: 4.5733, Accuracy: 0.4375\n",
      "Train-epoch 34. Iteration 01300, Avg-Loss: 4.5855, Accuracy: 0.4415\n",
      "Train-epoch 34. Iteration 01400, Avg-Loss: 4.5564, Accuracy: 0.4421\n",
      "Train-epoch 34. Iteration 01500, Avg-Loss: 4.5514, Accuracy: 0.4433\n",
      "Train-epoch 34. Iteration 01600, Avg-Loss: 4.4850, Accuracy: 0.4462\n",
      "Validation-epoch 34. Iteration 00426, Avg-Loss: 8.3831, Accuracy: 0.6541\n",
      "Train-epoch 35. Iteration 00100, Avg-Loss: 5.8973, Accuracy: 0.4100\n",
      "Train-epoch 35. Iteration 00200, Avg-Loss: 4.8726, Accuracy: 0.4350\n",
      "Train-epoch 35. Iteration 00300, Avg-Loss: 4.7645, Accuracy: 0.4433\n",
      "Train-epoch 35. Iteration 00400, Avg-Loss: 4.7251, Accuracy: 0.4625\n",
      "Train-epoch 35. Iteration 00500, Avg-Loss: 4.5161, Accuracy: 0.4620\n",
      "Train-epoch 35. Iteration 00600, Avg-Loss: 4.7203, Accuracy: 0.4483\n",
      "Train-epoch 35. Iteration 00700, Avg-Loss: 4.9272, Accuracy: 0.4386\n",
      "Train-epoch 35. Iteration 00800, Avg-Loss: 5.0515, Accuracy: 0.4213\n",
      "Train-epoch 35. Iteration 00900, Avg-Loss: 4.8345, Accuracy: 0.4278\n",
      "Train-epoch 35. Iteration 01000, Avg-Loss: 4.6318, Accuracy: 0.4410\n",
      "Train-epoch 35. Iteration 01100, Avg-Loss: 4.5022, Accuracy: 0.4482\n",
      "Train-epoch 35. Iteration 01200, Avg-Loss: 4.5186, Accuracy: 0.4508\n",
      "Train-epoch 35. Iteration 01300, Avg-Loss: 4.4787, Accuracy: 0.4492\n",
      "Train-epoch 35. Iteration 01400, Avg-Loss: 4.4458, Accuracy: 0.4486\n",
      "Train-epoch 35. Iteration 01500, Avg-Loss: 4.3757, Accuracy: 0.4540\n",
      "Train-epoch 35. Iteration 01600, Avg-Loss: 4.3302, Accuracy: 0.4556\n",
      "Validation-epoch 35. Iteration 00426, Avg-Loss: 5.5778, Accuracy: 0.6494\n",
      "Train-epoch 36. Iteration 00100, Avg-Loss: 5.4430, Accuracy: 0.4600\n",
      "Train-epoch 36. Iteration 00200, Avg-Loss: 4.8143, Accuracy: 0.4650\n",
      "Train-epoch 36. Iteration 00300, Avg-Loss: 4.2355, Accuracy: 0.4767\n",
      "Train-epoch 36. Iteration 00400, Avg-Loss: 4.0580, Accuracy: 0.4825\n",
      "Train-epoch 36. Iteration 00500, Avg-Loss: 4.1874, Accuracy: 0.4780\n",
      "Train-epoch 36. Iteration 00600, Avg-Loss: 4.0863, Accuracy: 0.4950\n",
      "Train-epoch 36. Iteration 00700, Avg-Loss: 4.0518, Accuracy: 0.5029\n",
      "Train-epoch 36. Iteration 00800, Avg-Loss: 4.0291, Accuracy: 0.5012\n",
      "Train-epoch 36. Iteration 00900, Avg-Loss: 4.1200, Accuracy: 0.4933\n",
      "Train-epoch 36. Iteration 01000, Avg-Loss: 4.2175, Accuracy: 0.4930\n",
      "Train-epoch 36. Iteration 01100, Avg-Loss: 4.4789, Accuracy: 0.4764\n",
      "Train-epoch 36. Iteration 01200, Avg-Loss: 4.5621, Accuracy: 0.4658\n",
      "Train-epoch 36. Iteration 01300, Avg-Loss: 4.5003, Accuracy: 0.4623\n",
      "Train-epoch 36. Iteration 01400, Avg-Loss: 4.4907, Accuracy: 0.4650\n",
      "Train-epoch 36. Iteration 01500, Avg-Loss: 4.5585, Accuracy: 0.4580\n",
      "Train-epoch 36. Iteration 01600, Avg-Loss: 4.6777, Accuracy: 0.4562\n",
      "Validation-epoch 36. Iteration 00426, Avg-Loss: 8.7309, Accuracy: 0.5835\n",
      "Train-epoch 37. Iteration 00100, Avg-Loss: 3.4437, Accuracy: 0.5700\n",
      "Train-epoch 37. Iteration 00200, Avg-Loss: 3.9447, Accuracy: 0.5150\n",
      "Train-epoch 37. Iteration 00300, Avg-Loss: 4.1824, Accuracy: 0.4700\n",
      "Train-epoch 37. Iteration 00400, Avg-Loss: 4.2778, Accuracy: 0.4675\n",
      "Train-epoch 37. Iteration 00500, Avg-Loss: 4.4297, Accuracy: 0.4520\n",
      "Train-epoch 37. Iteration 00600, Avg-Loss: 4.3217, Accuracy: 0.4633\n",
      "Train-epoch 37. Iteration 00700, Avg-Loss: 4.3041, Accuracy: 0.4714\n",
      "Train-epoch 37. Iteration 00800, Avg-Loss: 4.2960, Accuracy: 0.4700\n",
      "Train-epoch 37. Iteration 00900, Avg-Loss: 4.3606, Accuracy: 0.4622\n",
      "Train-epoch 37. Iteration 01000, Avg-Loss: 4.5757, Accuracy: 0.4460\n",
      "Train-epoch 37. Iteration 01100, Avg-Loss: 4.4041, Accuracy: 0.4582\n",
      "Train-epoch 37. Iteration 01200, Avg-Loss: 4.4561, Accuracy: 0.4542\n",
      "Train-epoch 37. Iteration 01300, Avg-Loss: 4.4320, Accuracy: 0.4554\n",
      "Train-epoch 37. Iteration 01400, Avg-Loss: 4.5619, Accuracy: 0.4507\n",
      "Train-epoch 37. Iteration 01500, Avg-Loss: 4.5461, Accuracy: 0.4507\n",
      "Train-epoch 37. Iteration 01600, Avg-Loss: 4.5061, Accuracy: 0.4537\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-3\n",
    "\n",
    "my_model = AverageModel(output_size=categories)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=learning_rate)\n",
    "epochs = 100\n",
    "\n",
    "train_model(my_model, loss_fn, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07935523868567886, 0.08617482951022938, 0.09671419714817112, 0.09547427154370738, 0.12337259764414135, 0.11841289522628642, 0.14879107253564786, 0.16181029138251704, 0.15933044017358958, 0.18412895226286422]\n",
      "[0.23058823529411765, 0.3058823529411765, 0.2211764705882353, 0.24235294117647058, 0.32941176470588235, 0.3035294117647059, 0.34823529411764703, 0.4541176470588235, 0.40705882352941175, 0.4376470588235294]\n"
     ]
    }
   ],
   "source": [
    "# These are not from the ones above. This was from an earlier run with only 10 epochs. \n",
    "print(train_accuracies)\n",
    "print(val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAEKCAYAAABNDBKGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9595cd07b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(val_losses, 'bo-', label = 'val-loss')\n",
    "plt.plot(train_losses, 'ro-', label = 'train-loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation', 'training'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, 'bo-', label = 'val-acc')\n",
    "plt.plot(train_accuracies, 'ro-', label = 'train-acc')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation', 'training'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 1.6, PyTorch 0.4, Keras",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
